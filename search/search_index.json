{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PyChebyshev","text":"<p>Fast multi-dimensional Chebyshev tensor interpolation with analytical derivatives.</p> <p>PyChebyshev builds a Chebyshev interpolant of any smooth function in up to N dimensions, then evaluates it and its derivatives in microseconds using vectorized NumPy operations. Four classes cover different use cases:</p> <ul> <li><code>ChebyshevApproximation</code> \u2014 full tensor interpolation with analytical derivatives (up to ~5 dimensions)</li> <li><code>ChebyshevSpline</code> \u2014 piecewise Chebyshev interpolation with knots at known singularities (kinks, discontinuities)</li> <li><code>ChebyshevTT</code> \u2014 Tensor Train format via TT-Cross for 5+ dimensions</li> <li><code>ChebyshevSlider</code> \u2014 additive decomposition for separable high-dimensional functions</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Spectral accuracy \u2014 exponential error decay as node count increases</li> <li>Chebyshev Splines \u2014 piecewise interpolation at kinks restores spectral convergence for non-smooth functions</li> <li>Arithmetic operators \u2014 combine interpolants via <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> for portfolio-level proxies</li> <li>Extrusion &amp; slicing \u2014 add or fix dimensions to combine interpolants across different risk-factor sets</li> <li>Integration, rootfinding &amp; optimization \u2014 spectral calculus directly on interpolants, no re-evaluation needed</li> <li>Analytical derivatives \u2014 via spectral differentiation matrices (no finite differences)</li> <li>Tensor Train \u2014 TT-Cross builds from O(d\u00b7n\u00b7r\u00b2) evaluations instead of O(n^d)</li> <li>Fast evaluation \u2014 ~0.065 ms per query (price), ~0.29 ms for price + 5 Greeks</li> <li>Save &amp; load \u2014 persist built interpolants to disk; rebuild-free deployment</li> <li>Pure Python \u2014 NumPy + SciPy only, no compiled extensions needed</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\n# Define any smooth function\ndef my_func(x, _):\n    return math.sin(x[0]) * math.exp(-x[1])\n\n# Build interpolant\ncheb = ChebyshevApproximation(\n    my_func,\n    num_dimensions=2,\n    domain=[[-1, 1], [0, 2]],\n    n_nodes=[15, 15],\n)\ncheb.build()\n\n# Evaluate\nvalue = cheb.vectorized_eval([0.5, 1.0], [0, 0])\n\n# First derivative with respect to x[0]\ndfdx = cheb.vectorized_eval([0.5, 1.0], [1, 0])\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pychebyshev\n</code></pre>"},{"location":"#performance","title":"Performance","text":"Method Price Error Greek Error Build Time Query Time Chebyshev Barycentric 0.000% 1.980% ~0.35s ~0.065ms Chebyshev TT 0.014% 0.029% ~0.35s ~0.004ms MoCaX Standard (C++) 0.000% 1.980% ~1.04s ~0.47ms FDM 0.803% 2.234% N/A ~500ms <p>Based on 5D Black-Scholes tests with 11 nodes per dimension. TT uses ~7,400 function evaluations (vs 161,051 for full tensor methods). See Benchmarks for detailed comparisons including MoCaX TT.</p>"},{"location":"benchmarks/","title":"Benchmarks","text":""},{"location":"benchmarks/#5d-black-scholes-performance","title":"5D Black-Scholes Performance","text":"<p>All benchmarks use 5D Black-Scholes: \\(V(S, K, T, \\sigma, r)\\) with 11 Chebyshev nodes per dimension (\\(11^5 = 161{,}051\\) grid points).</p>"},{"location":"benchmarks/#accuracy","title":"Accuracy","text":"Method Price Error Greek Error (max) Chebyshev Barycentric 0.000% 1.980% MoCaX Standard (C++) 0.000% 1.980% FDM (Crank-Nicolson) 0.803% 2.234% <p>Both Chebyshev methods achieve machine-precision price accuracy and identical Greek errors, as they compute the same unique interpolating polynomial.</p>"},{"location":"benchmarks/#timing","title":"Timing","text":"Method Build Time Price Query Price + 5 Greeks Chebyshev Barycentric 0.35s 0.065 ms 0.29 ms MoCaX Standard (C++) 1.04s 0.47 ms 2.85 ms Analytical (direct) N/A 0.01 ms 0.06 ms"},{"location":"benchmarks/#evaluation-method-comparison","title":"Evaluation Method Comparison","text":"<p>Within PyChebyshev, multiple evaluation paths exist:</p> Method Price Only Price + 5 Greeks Notes <code>eval()</code> ~45 ms ~270 ms Python loops, full validation <code>fast_eval()</code> ~10 ms ~95 ms Deprecated \u2014 JIT scalar loops <code>vectorized_eval()</code> 0.065 ms 0.39 ms Recommended \u2014 BLAS GEMV <code>vectorized_eval_multi()</code> \u2014 0.29 ms Shared weights across derivatives <p><code>vectorized_eval()</code> is the recommended default. Use <code>vectorized_eval_multi()</code> when computing multiple derivatives at the same point.</p> <p>Why BLAS beats JIT</p> <p><code>fast_eval()</code> uses Numba JIT to compile scalar barycentric interpolation loops. But <code>vectorized_eval()</code> restructures the algorithm into matrix-vector products (BLAS GEMV), replacing 16,105 Python loop iterations with 5 BLAS calls for a 5D problem. Optimized BLAS (OpenBLAS/MKL) running a single GEMV is fundamentally faster than JIT-compiled scalar loops \u2014 the data access pattern is more cache-friendly and leverages SIMD vectorization at the hardware level. <code>fast_eval()</code> is deprecated and will be removed in a future version.</p>"},{"location":"benchmarks/#tensor-train-tt-vs-mocax-extend","title":"Tensor Train (TT) vs MoCaX Extend","text":"<p><code>ChebyshevTT</code> and MoCaX <code>MocaxExtend</code> both build Chebyshev interpolants in TT format for the same 5D Black-Scholes problem. PyChebyshev uses TT-Cross (maxvol pivoting); MoCaX uses rank-adaptive ALS on a random subgrid. Both use ~7,400--8,000 function evaluations.</p>"},{"location":"benchmarks/#build","title":"Build","text":"Metric PyChebyshev TT MoCaX TT Build time 0.35s 5.73s Function evaluations 7,419 8,000 TT ranks [1, 11, 11, 11, 7, 1] (not exposed) Compression ratio 43.4x N/A"},{"location":"benchmarks/#price-accuracy-50-random-test-points","title":"Price Accuracy (50 random test points)","text":"Metric PyChebyshev TT MoCaX TT Mean error 0.002% 0.093% Max error 0.014% 0.712% Median error 0.001% 0.045%"},{"location":"benchmarks/#evaluation-speed-1000-random-points","title":"Evaluation Speed (1000 random points)","text":"Method PyChebyshev TT MoCaX TT Single eval 0.065 ms -- Batch eval 0.004 ms 0.246 ms"},{"location":"benchmarks/#greeks-accuracy-10-scenarios-fd-vs-analytical","title":"Greeks Accuracy (10 scenarios, FD vs analytical)","text":"Greek PyChebyshev avg error MoCaX avg error Delta 0.029% 0.379% Gamma 0.019% 1.604% <p>To reproduce: <code>uv run --with tqdm --with blackscholes python compare_tensor_train.py</code> (requires MoCaX C++ library; PyChebyshev results are shown regardless).</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#from-pypi","title":"From PyPI","text":"<pre><code>pip install pychebyshev\n</code></pre>"},{"location":"getting-started/#from-source-development","title":"From source (development)","text":"<pre><code>git clone https://github.com/0xC000005/PyChebyshev.git\ncd PyChebyshev\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":""},{"location":"getting-started/#1-define-your-function","title":"1. Define your function","text":"<p>PyChebyshev can approximate any smooth function. The function signature is <code>f(point, data) -&gt; float</code>, where <code>point</code> is a list of coordinates and <code>data</code> is optional additional data (pass <code>None</code> if unused).</p> <pre><code>import math\n\ndef my_func(x, _):\n    return math.sin(x[0]) + math.cos(x[1])\n</code></pre>"},{"location":"getting-started/#2-build-the-interpolant","title":"2. Build the interpolant","text":"<pre><code>from pychebyshev import ChebyshevApproximation\n\ncheb = ChebyshevApproximation(\n    function=my_func,\n    num_dimensions=2,\n    domain=[[-3, 3], [-3, 3]],  # bounds per dimension\n    n_nodes=[15, 15],            # Chebyshev nodes per dimension\n)\ncheb.build()\n</code></pre>"},{"location":"getting-started/#3-evaluate","title":"3. Evaluate","text":"<pre><code># Function value\nvalue = cheb.vectorized_eval([1.0, 2.0], [0, 0])\n\n# First derivative w.r.t. x[0]\ndfdx0 = cheb.vectorized_eval([1.0, 2.0], [1, 0])\n\n# Second derivative w.r.t. x[1]\nd2fdx1 = cheb.vectorized_eval([1.0, 2.0], [0, 2])\n</code></pre>"},{"location":"getting-started/#4-evaluate-price-all-greeks-at-once","title":"4. Evaluate price + all Greeks at once","text":"<p>For maximum efficiency when computing multiple derivatives at the same point:</p> <pre><code>results = cheb.vectorized_eval_multi(\n    [1.0, 2.0],\n    [\n        [0, 0],  # function value\n        [1, 0],  # df/dx0\n        [0, 1],  # df/dx1\n        [2, 0],  # d2f/dx0^2\n    ],\n)\n# results = [value, dfdx0, dfdx1, d2fdx0]\n</code></pre> <p>This shares barycentric weights across all derivative orders, saving ~25% compared to separate calls.</p>"},{"location":"getting-started/#5-save-for-later","title":"5. Save for later","text":"<p>Save the built interpolant to skip rebuilding next time:</p> <pre><code>cheb.save(\"my_interpolant.pkl\")\n</code></pre> <p>Load it back \u2014 no rebuild needed:</p> <pre><code>from pychebyshev import ChebyshevApproximation\n\ncheb = ChebyshevApproximation.load(\"my_interpolant.pkl\")\nvalue = cheb.vectorized_eval([1.0, 2.0], [0, 0])\n</code></pre> <p>See Saving &amp; Loading for details.</p>"},{"location":"getting-started/#choosing-node-counts","title":"Choosing Node Counts","text":"<ul> <li>10-15 nodes per dimension is typical for smooth analytic functions</li> <li>More nodes = higher accuracy but more build-time evaluations (\\(n_1 \\times n_2 \\times \\cdots\\))</li> <li>For 5D with 11 nodes: \\(11^5 = 161{,}051\\) function evaluations at build time</li> <li>Convergence is exponential for analytic functions \u2014 a few extra nodes can eliminate errors entirely</li> </ul>"},{"location":"getting-started/#choosing-the-right-class","title":"Choosing the Right Class","text":"Class Dimensions Build Cost Derivatives Best For <code>ChebyshevApproximation</code> 1--5 \\(n^d\\) evals Analytical Full accuracy with spectral derivatives <code>ChebyshevSpline</code> 1--5 \\(\\text{pieces} \\times n^d\\) evals Analytical (per piece) Functions with kinks at known locations <code>ChebyshevTT</code> 5+ \\(O(d \\cdot n \\cdot r^2)\\) evals Finite differences High-dimensional problems where full grids are infeasible <code>ChebyshevSlider</code> 5+ Sum of slide grids Analytical (per slide) Functions with additive/separable structure"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Computing Greeks -- analytical derivatives for pricing</li> <li>Chebyshev Algebra -- combine interpolants via <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></li> <li>Extrusion &amp; Slicing -- add/fix dimensions to combine interpolants on different risk-factor sets</li> <li>Chebyshev Calculus -- integration, rootfinding &amp; optimization on interpolants</li> <li>Error Estimation -- validate accuracy without test points</li> <li>Saving &amp; Loading -- persist built interpolants</li> <li>Benchmarks -- performance comparison with MoCaX C++</li> </ul>"},{"location":"api/reference/","title":"API Reference","text":""},{"location":"api/reference/#chebyshevapproximation","title":"ChebyshevApproximation","text":"<p>Multi-dimensional Chebyshev approximation using barycentric interpolation.</p> <p>Pre-computes barycentric weights for all dimensions at build time, enabling uniform O(N) evaluation complexity for every dimension. Supports analytical derivatives via spectral differentiation matrices.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate. Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [(lo, hi), ...] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension.</p> required <code>max_derivative_order</code> <code>int</code> <p>Maximum derivative order to support. Default is 2.</p> <code>2</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return math.sin(x[0]) + math.sin(x[1])\n&gt;&gt;&gt; cheb = ChebyshevApproximation(f, 2, [[-1, 1], [-1, 1]], [11, 11])\n&gt;&gt;&gt; cheb.build()\n&gt;&gt;&gt; cheb.vectorized_eval([0.5, 0.3], [0, 0])\n0.7764...\n</code></pre>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.build","title":"<code>build(verbose=True)</code>","text":"<p>Evaluate the function at all node combinations and pre-compute weights.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress. Default is True.</p> <code>True</code>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.eval","title":"<code>eval(point, derivative_order)</code>","text":"<p>Evaluate using dimensional decomposition with barycentric interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Query point, one coordinate per dimension.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order per dimension (0 = function value, 1 = first derivative, 2 = second derivative).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Interpolated value or derivative at the query point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.fast_eval","title":"<code>fast_eval(point, derivative_order)</code>","text":"<p>Fast evaluation using pre-allocated cache (skips validation).</p> <p>.. deprecated:: 0.3.0     Use :meth:<code>vectorized_eval</code> instead, which is ~150x faster via     BLAS GEMV and requires no optional dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Query point.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Interpolated value or derivative.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.vectorized_eval","title":"<code>vectorized_eval(point, derivative_order)</code>","text":"<p>Fully vectorized evaluation using NumPy matrix operations.</p> <p>Replaces the Python loop with BLAS matrix-vector products. For 5-D with 11 nodes: 5 BLAS calls instead of 16,105 Python iterations.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Query point, one coordinate per dimension.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Interpolated value or derivative.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.vectorized_eval_batch","title":"<code>vectorized_eval_batch(points, derivative_order)</code>","text":"<p>Evaluate at multiple points.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>Points of shape (N, num_dimensions).</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Results of shape (N,).</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.vectorized_eval_multi","title":"<code>vectorized_eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate multiple derivative orders at the same point, sharing weights.</p> <p>Pre-computes normalized barycentric weights once per dimension and reuses them across all derivative orders. Computing price + 5 Greeks costs ~0.29 ms instead of 6 x 0.065 ms = 0.39 ms.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Query point.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>One result per derivative order.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.get_derivative_id","title":"<code>get_derivative_id(derivative_order)</code>","text":"<p>Return derivative order as-is (for API compatibility).</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate the supremum-norm interpolation error.</p> <p>Computes Chebyshev expansion coefficients via DCT-II for each 1-D slice of the tensor, and returns the sum of per-dimension maximum last-coefficient magnitudes:</p> <p>.. math::</p> <pre><code>\\hat{E} = \\sum_{d=1}^{D}\n    \\max_{\\text{slices along } d} |c_{n_d - 1}|\n</code></pre> <p>This follows the ex ante error estimation from Ruiz &amp; Zeron (2021), Section 3.4, adapted for Type I Chebyshev nodes.</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated maximum interpolation error (sup-norm).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function and eval cache.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state and reconstruct the eval cache.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.save","title":"<code>save(path)</code>","text":"<p>Save the built interpolant to a file.</p> <p>The original function is not saved \u2014 only the numerical data needed for evaluation. The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the interpolant has not been built yet.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved interpolant from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>. Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevApproximation</code> <p>The restored interpolant.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally. Pickle can execute arbitrary code during deserialization. Only load files you trust.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.extrude","title":"<code>extrude(params)</code>","text":"<p>Add new dimensions where the function is constant.</p> <p>The extruded interpolant evaluates identically to the original regardless of the new coordinate(s), because Chebyshev basis functions form a partition of unity: the barycentric weights sum to 1, so replicating tensor values along a new axis produces the same result for any coordinate in the new domain.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, (lo, hi), n_nodes)</code> or a list of such tuples.  <code>dim_index</code> is the position in the output space (0-indexed).  <code>n_nodes</code> must be &gt;= 2 and <code>lo &lt; hi</code>.</p> required <p>Returns:</p> Type Description <code>ChebyshevApproximation</code> <p>A new, higher-dimensional interpolant (already built). The result has <code>function=None</code> and <code>build_time=0.0</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the interpolant has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If <code>dim_index</code> is out of range, duplicated, <code>lo &gt;= hi</code>, or <code>n_nodes &lt; 2</code>.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.slice","title":"<code>slice(params)</code>","text":"<p>Fix one or more dimensions at given values, reducing dimensionality.</p> <p>Contracts the tensor along each sliced dimension using the barycentric interpolation formula: for each sliced axis the normalized weight vector <code>w_i / (x - x_i) / sum(w_j / (x - x_j))</code> is contracted with the tensor via <code>np.tensordot</code>.  When the slice value coincides with a Chebyshev node (within 1e-14), the contraction reduces to an exact <code>np.take</code> (fast path).</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, value)</code> or a list of such tuples. <code>value</code> must lie within the domain for that dimension.</p> required <p>Returns:</p> Type Description <code>ChebyshevApproximation</code> <p>A new, lower-dimensional interpolant (already built). The result has <code>function=None</code> and <code>build_time=0.0</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the interpolant has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If a slice value is outside the domain, if slicing all dimensions, or if <code>dim_index</code> is out of range or duplicated.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.integrate","title":"<code>integrate(dims=None)</code>","text":"<p>Integrate the interpolant over one or more dimensions.</p> <p>Uses Fej\u00e9r-1 quadrature weights (Waldvogel 2006) at Chebyshev Type I nodes, computed in O(n log n) via DCT-III.  For multi-D tensors, each dimension is contracted via <code>np.tensordot</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>int, list of int, or None</code> <p>Dimensions to integrate out.  If <code>None</code>, integrates over all dimensions and returns a scalar.</p> <code>None</code> <p>Returns:</p> Type Description <code>float or ChebyshevApproximation</code> <p>If all dimensions are integrated, returns the scalar integral. Otherwise returns a lower-dimensional interpolant.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If any dimension index is out of range or duplicated.</p> References <p>Waldvogel (2006), \"Fast Construction of the Fej\u00e9r and Clenshaw\u2013Curtis Quadrature Rules\", BIT Numer. Math. 46(2):195\u2013202.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.roots","title":"<code>roots(dim=None, fixed=None)</code>","text":"<p>Find all roots of the interpolant along a specified dimension.</p> <p>Uses the colleague matrix eigenvalue method (Good 1961) via <code>numpy.polynomial.chebyshev.chebroots</code>.  For multi-D interpolants, all dimensions except the target must be fixed at specific values (the interpolant is sliced to 1-D first).</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to find roots.  For 1-D interpolants, defaults to 0.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D interpolants, a dict <code>{dim_index: value}</code> for all dimensions except dim.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted array of root locations in the physical domain.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails or values are out of domain.</p> References <p>Good (1961), \"The colleague matrix\", Quarterly J. Mech. 14:195\u2013196. Trefethen (2013), \"Approximation Theory and Approximation Practice\", SIAM, Chapter 18.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.minimize","title":"<code>minimize(dim=None, fixed=None)</code>","text":"<p>Find the minimum value of the interpolant along a dimension.</p> <p>Computes derivative roots to locate critical points, then evaluates the interpolant at all critical points and domain endpoints.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to minimize.  Defaults to 0 for 1-D.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>(value, location) : (float, float)</code> <p>The minimum value and its coordinate in the target dimension.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p> References <p>Trefethen (2013), \"Approximation Theory and Approximation Practice\", SIAM, Chapter 18.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevApproximation.maximize","title":"<code>maximize(dim=None, fixed=None)</code>","text":"<p>Find the maximum value of the interpolant along a dimension.</p> <p>Computes derivative roots to locate critical points, then evaluates the interpolant at all critical points and domain endpoints.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to maximize.  Defaults to 0 for 1-D.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>(value, location) : (float, float)</code> <p>The maximum value and its coordinate in the target dimension.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p> References <p>Trefethen (2013), \"Approximation Theory and Approximation Practice\", SIAM, Chapter 18.</p>"},{"location":"api/reference/#chebyshevslider","title":"ChebyshevSlider","text":"<p>Chebyshev Sliding approximation for high-dimensional functions.</p> <p>Decomposes f(x_1, ..., x_n) into a sum of low-dimensional Chebyshev interpolants (slides) around a pivot point z:</p> <pre><code>f(x) \u2248 f(z) + \u03a3_i [s_i(x_group_i) - f(z)]\n</code></pre> <p>where each slide s_i is a ChebyshevApproximation built on a subset of dimensions with the remaining dimensions fixed at z.</p> <p>This trades accuracy for dramatically reduced build cost: instead of evaluating f at n_1 \u00d7 n_2 \u00d7 ... \u00d7 n_d grid points (exponential), the slider evaluates at n_1 \u00d7 n_2 + n_3 \u00d7 n_4 + ... (sum of products within each group).</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate. Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Total number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [lo, hi] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension.</p> required <code>partition</code> <code>list of list of int</code> <p>Grouping of dimension indices into slides. Each dimension must appear in exactly one group. E.g. <code>[[0,1,2], [3,4]]</code> creates a 3D slide for dims 0,1,2 and a 2D slide for dims 3,4.</p> required <code>pivot_point</code> <code>list of float</code> <p>Reference point z around which slides are built.</p> required <code>max_derivative_order</code> <code>int</code> <p>Maximum derivative order to pre-compute (default 2).</p> <code>2</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return math.sin(x[0]) + math.sin(x[1]) + math.sin(x[2])\n&gt;&gt;&gt; slider = ChebyshevSlider(\n...     f, 3, [[-1,1], [-1,1], [-1,1]], [11,11,11],\n...     partition=[[0], [1], [2]],\n...     pivot_point=[0.0, 0.0, 0.0],\n... )\n&gt;&gt;&gt; slider.build(verbose=False)\n&gt;&gt;&gt; round(slider.eval([0.5, 0.3, 0.1], [0,0,0]), 4)\n0.8764\n</code></pre>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.total_build_evals","title":"<code>total_build_evals</code>  <code>property</code>","text":"<p>Total number of function evaluations used during build.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.build","title":"<code>build(verbose=True)</code>","text":"<p>Build all slides by evaluating the function at slide-specific grids.</p> <p>For each slide, dimensions outside the slide group are fixed at their pivot values.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress. Default is True.</p> <code>True</code>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.eval","title":"<code>eval(point, derivative_order)</code>","text":"<p>Evaluate the slider approximation at a point.</p> <p>Uses Equation 7.5 from Ruiz &amp; Zeron (2021):     f(x) \u2248 f(z) + \u03a3_i [s_i(x_i) - f(z)]</p> <p>For derivatives, only the slide containing that dimension contributes.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full n-dimensional space.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order for each dimension (0 = function value).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Approximated function value or derivative.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.eval_multi","title":"<code>eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate slider at multiple derivative orders for the same point.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full n-dimensional space.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>Results for each derivative order.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate the sliding approximation error.</p> <p>Returns the sum of per-slide Chebyshev error estimates. Each slide's error is estimated independently using the Chebyshev coefficient method from Ruiz &amp; Zeron (2021), Section 3.4.</p> <p>Note: This captures per-slide interpolation error only. Cross-group interaction error (inherent to the sliding decomposition) is not included.</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated interpolation error (per-slide sum).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state from a pickled dict.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.save","title":"<code>save(path)</code>","text":"<p>Save the built slider to a file.</p> <p>The original function is not saved \u2014 only the numerical data needed for evaluation. The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the slider has not been built yet.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved slider from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>. Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevSlider</code> <p>The restored slider.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally. Pickle can execute arbitrary code during deserialization. Only load files you trust.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.extrude","title":"<code>extrude(params)</code>","text":"<p>Add new dimensions where the function is constant.</p> <p>Each new dimension becomes its own single-dim slide group with <code>tensor_values = np.full(n, pivot_value)</code>, so that <code>s_new(x) - pivot_value = 0</code> for all x (no contribution to the sliding sum).  This is the partition-of-unity property: the barycentric weights sum to 1, so a constant tensor produces the same value for any coordinate.</p> <p>Existing slide groups have their dimension indices remapped to account for the inserted dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, (lo, hi), n_nodes)</code> or a list of such tuples.  <code>dim_index</code> is the position in the output space (0-indexed).  <code>n_nodes</code> must be &gt;= 2 and <code>lo &lt; hi</code>.</p> required <p>Returns:</p> Type Description <code>ChebyshevSlider</code> <p>A new, higher-dimensional slider (already built). The result has <code>function=None</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the slider has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If <code>dim_index</code> is out of range, duplicated, <code>lo &gt;= hi</code>, or <code>n_nodes &lt; 2</code>.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSlider.slice","title":"<code>slice(params)</code>","text":"<p>Fix one or more dimensions at given values, reducing dimensionality.</p> <p>Two cases per sliced dimension:</p> <ul> <li>Multi-dim group: The slide's <code>ChebyshevApproximation</code> is   sliced at the local dimension index via barycentric contraction.   When the slice value coincides with a Chebyshev node (within   1e-14), the contraction reduces to an exact <code>np.take</code>   (fast path).  The dimension is removed from the group.</li> <li>Single-dim group: The slide is evaluated at the value,   giving a constant <code>s_val</code>.  The shift   <code>delta = s_val - pivot_value</code> is absorbed into   <code>pivot_value</code> and each remaining slide's   <code>tensor_values</code>, and the group is removed entirely.</li> </ul> <p>Remaining dimension indices in all groups are remapped downward to stay contiguous.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, value)</code> or a list of such tuples. <code>value</code> must lie within the domain for that dimension.</p> required <p>Returns:</p> Type Description <code>ChebyshevSlider</code> <p>A new, lower-dimensional slider (already built). The result has <code>function=None</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the slider has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If a slice value is outside the domain, if slicing all dimensions, or if <code>dim_index</code> is out of range or duplicated.</p>"},{"location":"api/reference/#chebyshevspline","title":"ChebyshevSpline","text":"<p>Piecewise Chebyshev interpolation with user-specified knots.</p> <p>Partitions the domain into sub-intervals at interior knots and builds an independent :class:<code>ChebyshevApproximation</code> on each piece.  Query points are routed to the appropriate piece for evaluation.</p> <p>This is the correct approach when the target function has known singularities (kinks, discontinuities) at specific locations: place knots at those locations so that each piece is smooth, restoring spectral convergence.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate.  Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [lo, hi] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension per piece.</p> required <code>knots</code> <code>list of list of float</code> <p>Interior knots for each dimension.  Each sub-list must be sorted and every knot must lie strictly inside the corresponding domain interval.  Use an empty list <code>[]</code> for dimensions with no knots.</p> required <code>max_derivative_order</code> <code>int</code> <p>Maximum derivative order to pre-compute (default 2).</p> <code>2</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return abs(x[0])\n&gt;&gt;&gt; sp = ChebyshevSpline(f, 1, [[-1, 1]], [15], [[0.0]])\n&gt;&gt;&gt; sp.build(verbose=False)\n&gt;&gt;&gt; round(sp.eval([0.5], [0]), 10)\n0.5\n&gt;&gt;&gt; round(sp.eval([-0.3], [0]), 10)\n0.3\n</code></pre>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.num_pieces","title":"<code>num_pieces</code>  <code>property</code>","text":"<p>Total number of pieces (Cartesian product of per-dimension intervals).</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.total_build_evals","title":"<code>total_build_evals</code>  <code>property</code>","text":"<p>Total number of function evaluations used during build.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.build_time","title":"<code>build_time</code>  <code>property</code>","text":"<p>Wall-clock time (seconds) for the most recent <code>build()</code> call.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.build","title":"<code>build(verbose=True)</code>","text":"<p>Build all pieces by evaluating the function on each sub-domain.</p> <p>Each piece is an independent :class:<code>ChebyshevApproximation</code> built on the Cartesian product of per-dimension sub-intervals.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress.  Default is True.</p> <code>True</code>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.eval","title":"<code>eval(point, derivative_order)</code>","text":"<p>Evaluate the spline approximation at a point.</p> <p>Routes the query to the piece whose sub-domain contains <code>point</code> and delegates to its :meth:<code>~ChebyshevApproximation.vectorized_eval</code>.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full domain.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order for each dimension (0 = function value).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Approximated function value or derivative.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If the point is at a knot and a non-zero derivative is requested.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.eval_multi","title":"<code>eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate multiple derivative orders at one point, sharing weights.</p> <p>Routes to a single piece and delegates to its :meth:<code>~ChebyshevApproximation.vectorized_eval_multi</code> so that barycentric weight computation is shared across all requested derivative orders.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full domain.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>One result per derivative order.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If the point is at a knot and a non-zero derivative is requested.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.eval_batch","title":"<code>eval_batch(points, derivative_order)</code>","text":"<p>Evaluate at multiple points, grouping by piece for efficiency.</p> <p>Vectorises the piece-routing step using <code>np.searchsorted</code> and evaluates each piece's batch via :meth:<code>~ChebyshevApproximation.vectorized_eval_batch</code>.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray of shape (N, num_dimensions)</code> <p>Evaluation points.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order for each dimension.</p> required <p>Returns:</p> Type Description <code>ndarray of shape (N,)</code> <p>Approximated values or derivatives at each point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate the supremum-norm interpolation error.</p> <p>Returns the maximum error estimate across all pieces.  Since pieces cover disjoint sub-domains, the interpolation error at any point is bounded by the error of the piece containing that point. The worst-case error is therefore the maximum over all pieces (not the sum, unlike :class:<code>ChebyshevSlider</code> where all slides contribute to every point).</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated maximum interpolation error (sup-norm).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state from a pickled dict.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.save","title":"<code>save(path)</code>","text":"<p>Save the built spline to a file.</p> <p>The original function is not saved -- only the numerical data needed for evaluation.  The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the spline has not been built yet.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved spline from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>.  Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevSpline</code> <p>The restored spline.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally.  Pickle can execute arbitrary code during deserialization.  Only load files you trust.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.extrude","title":"<code>extrude(params)</code>","text":"<p>Add new dimensions where the function is constant.</p> <p>Each piece is extruded independently via :meth:<code>ChebyshevApproximation.extrude</code>.  The extruded spline evaluates identically to the original regardless of the new coordinate(s), because Chebyshev basis functions form a partition of unity.  The new dimension gets <code>knots=[]</code> and a single interval <code>(lo, hi)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, (lo, hi), n_nodes)</code> or a list of such tuples.  <code>dim_index</code> is the position in the output space (0-indexed).  <code>n_nodes</code> must be &gt;= 2 and <code>lo &lt; hi</code>.</p> required <p>Returns:</p> Type Description <code>ChebyshevSpline</code> <p>A new, higher-dimensional spline (already built). The result has <code>function=None</code> and <code>build_time=0.0</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the spline has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If <code>dim_index</code> is out of range, duplicated, <code>lo &gt;= hi</code>, or <code>n_nodes &lt; 2</code>.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.slice","title":"<code>slice(params)</code>","text":"<p>Fix one or more dimensions at given values, reducing dimensionality.</p> <p>For each sliced dimension, only the pieces whose interval contains the slice value survive.  Each surviving piece is then sliced via :meth:<code>ChebyshevApproximation.slice</code>, which contracts the tensor along that axis using the barycentric interpolation formula.  When the slice value coincides with a Chebyshev node (within 1e-14), the contraction reduces to an exact <code>np.take</code> (fast path).</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, value)</code> or a list of such tuples. <code>value</code> must lie within the domain for that dimension.</p> required <p>Returns:</p> Type Description <code>ChebyshevSpline</code> <p>A new, lower-dimensional spline (already built). The result has <code>function=None</code> and <code>build_time=0.0</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the spline has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If a slice value is outside the domain, if slicing all dimensions, or if <code>dim_index</code> is out of range or duplicated.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.integrate","title":"<code>integrate(dims=None)</code>","text":"<p>Integrate the spline over one or more dimensions.</p> <p>For full integration, sums the integrals of each piece (pieces cover disjoint sub-domains).  For partial integration, pieces along the integrated dimension are summed and the result is a lower-dimensional spline.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>int, list of int, or None</code> <p>Dimensions to integrate out.  If <code>None</code>, integrates over all dimensions and returns a scalar.</p> <code>None</code> <p>Returns:</p> Type Description <code>float or ChebyshevSpline</code> <p>Scalar for full integration; lower-dimensional spline for partial integration.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If any dimension index is out of range or duplicated.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.roots","title":"<code>roots(dim=None, fixed=None)</code>","text":"<p>Find all roots of the spline along a specified dimension.</p> <p>Slices the spline to 1-D, then finds roots in each piece and merges the results.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to find roots.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted array of root locations in the physical domain.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.minimize","title":"<code>minimize(dim=None, fixed=None)</code>","text":"<p>Find the minimum value of the spline along a dimension.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to minimize.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>(value, location) : (float, float)</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevSpline.maximize","title":"<code>maximize(dim=None, fixed=None)</code>","text":"<p>Find the maximum value of the spline along a dimension.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to maximize.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>(value, location) : (float, float)</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p>"},{"location":"api/reference/#chebyshevtt","title":"ChebyshevTT","text":"<p>Chebyshev interpolation in Tensor Train format.</p> <p>For functions of 5+ dimensions where full tensor interpolation is infeasible. Uses TT-Cross to build from O(d * n * r^2) function evaluations instead of O(n^d), then evaluates via TT inner product.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate. Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [(lo, hi), ...] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension.</p> required <code>max_rank</code> <code>int</code> <p>Maximum TT rank. Higher = more accurate, more expensive. Default is 10.</p> <code>10</code> <code>tolerance</code> <code>float</code> <p>Convergence tolerance for TT-Cross. Default is 1e-6.</p> <code>1e-06</code> <code>max_sweeps</code> <code>int</code> <p>Maximum number of TT-Cross sweeps. Default is 10.</p> <code>10</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return math.sin(x[0]) + math.sin(x[1]) + math.sin(x[2])\n&gt;&gt;&gt; tt = ChebyshevTT(f, 3, [[-1, 1], [-1, 1], [-1, 1]], [11, 11, 11])\n&gt;&gt;&gt; tt.build(verbose=False)\n&gt;&gt;&gt; tt.eval([0.5, 0.3, 0.1])\n0.8764...\n</code></pre>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.tt_ranks","title":"<code>tt_ranks</code>  <code>property</code>","text":"<p>TT ranks [1, r_1, r_2, ..., r_{d-1}, 1].</p> <p>Returns:</p> Type Description <code>list of int</code> <p>The TT rank vector. Only available after :meth:<code>build</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.compression_ratio","title":"<code>compression_ratio</code>  <code>property</code>","text":"<p>Ratio of full tensor elements to TT storage elements.</p> <p>Returns:</p> Type Description <code>float</code> <p>Compression ratio (&gt; 1 means TT is more compact).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.total_build_evals","title":"<code>total_build_evals</code>  <code>property</code>","text":"<p>Total number of function evaluations used during build.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of function evaluations. Only meaningful after :meth:<code>build</code>.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.build","title":"<code>build(verbose=True, seed=None, method='cross')</code>","text":"<p>Build TT approximation and convert to Chebyshev coefficient cores.</p> <p>The build process has three stages:</p> <ol> <li>Generate Chebyshev grids. Compute Type I Chebyshev nodes    in each dimension, scaled to the specified domain.</li> <li>Build value cores. Either TT-Cross (evaluating at    \\(O(d \\cdot n \\cdot r^2)\\) strategically selected points) or    TT-SVD (evaluating the full \\(O(n^d)\\) tensor, then decomposing    via sequential SVD).</li> <li>Convert to coefficient cores. Apply DCT-II along the node    axis of each core to convert from function values at Chebyshev    nodes to Chebyshev expansion coefficients. This enables    evaluation at arbitrary (non-grid) points via the Chebyshev    polynomial inner product.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress. Default is True.</p> <code>True</code> <code>seed</code> <code>int or None</code> <p>Random seed for TT-Cross initialization. Default is None. Ignored when <code>method='svd'</code>.</p> <code>None</code> <code>method</code> <code>``'cross'`` or ``'svd'``</code> <p>Build algorithm. <code>'cross'</code> (default) uses TT-Cross to evaluate the function at \\(O(d \\cdot n \\cdot r^2)\\) strategically selected points. <code>'svd'</code> builds the full tensor and decomposes via truncated SVD -- only feasible for moderate dimensions (\\(d \\leq 6\\)) but useful for validation.</p> <code>'cross'</code>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.eval","title":"<code>eval(point)</code>","text":"<p>Evaluate at a single point via TT inner product.</p> <p>Computes the Chebyshev interpolant value at an arbitrary point by contracting the pre-computed coefficient cores with Chebyshev polynomial values. For each dimension \\(k\\):</p> <ol> <li>Scale the query coordinate to \\([-1, 1]\\).</li> <li>Evaluate all Chebyshev polynomials \\(T_0, \\ldots, T_{n_k-1}\\).</li> <li>Contract with the coefficient core:    \\(v = \\sum_j q_j \\cdot \\text{core}[:, j, :]\\)</li> </ol> <p>The chain of contractions reduces to a scalar. Cost: \\(O(d \\cdot n \\cdot r^2)\\) per point.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Query point, one coordinate per dimension.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Interpolated value at the query point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.eval_batch","title":"<code>eval_batch(points)</code>","text":"<p>Evaluate at multiple points simultaneously.</p> <p>Vectorizes the TT inner product over all N points using <code>np.einsum</code> for batched matrix contractions. For each dimension, all N polynomial vectors are contracted with the coefficient core in a single einsum call, then all N chain multiplications proceed in parallel. Typical speedup is 15--20x over calling :meth:<code>eval</code> in a loop.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray of shape (N, num_dimensions)</code> <p>Query points.</p> required <p>Returns:</p> Type Description <code>ndarray of shape (N,)</code> <p>Interpolated values at each query point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.eval_multi","title":"<code>eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate with finite-difference derivatives at a single point.</p> <p>Uses central finite differences. The first entry in <code>derivative_orders</code> is typically <code>[0, 0, ..., 0]</code> for the function value; subsequent entries specify derivative orders per dimension.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full n-dimensional space.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension. Supports 0 (value), 1 (first derivative), and 2 (second derivative).</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>One result per derivative order specification.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate interpolation error from Chebyshev coefficient cores.</p> <p>For each dimension d, takes the maximum magnitude of the last Chebyshev coefficient across all \"rows\" and \"columns\" of the core (i.e., max over left-rank and right-rank indices of <code>|core[:, -1, :]|</code>). Returns the sum across dimensions.</p> <p>This is an approximate analog of the ex ante error estimation from Ruiz &amp; Zeron (2021), Section 3.4, adapted for TT format.</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated interpolation error.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state from a pickled dict.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.save","title":"<code>save(path)</code>","text":"<p>Save the built TT interpolant to a file.</p> <p>The original function is not saved -- only the numerical data needed for evaluation. The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"api/reference/#pychebyshev.ChebyshevTT.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved TT interpolant from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>. Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevTT</code> <p>The restored TT interpolant.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally. Pickle can execute arbitrary code during deserialization. Only load files you trust.</p>"},{"location":"api/reference/#module-functions","title":"Module Functions","text":"<p>Compute barycentric weights for given nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>ndarray</code> <p>Interpolation nodes of shape (n,).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Barycentric weights w_i = 1 / prod_{j!=i} (x_i - x_j).</p> <p>Compute spectral differentiation matrix for barycentric interpolation.</p> <p>Based on Berrut &amp; Trefethen (2004), Section 9.3.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>ndarray</code> <p>Interpolation nodes of shape (n,).</p> required <code>weights</code> <code>ndarray</code> <p>Barycentric weights of shape (n,).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Differentiation matrix D of shape (n, n) such that D @ f gives derivative values at nodes.</p> <p>Evaluate barycentric interpolation at a single point.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>Evaluation point.</p> required <code>nodes</code> <code>ndarray</code> <p>Interpolation nodes.</p> required <code>values</code> <code>ndarray</code> <p>Function values at nodes.</p> required <code>weights</code> <code>ndarray</code> <p>Barycentric weights.</p> required <code>skip_check</code> <code>bool</code> <p>If True, skip node coincidence check (faster but may divide by zero).</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> <p>Interpolated value p(x).</p>"},{"location":"user-guide/algebra/","title":"Chebyshev Algebra","text":""},{"location":"user-guide/algebra/#motivation-portfolio-combination","title":"Motivation -- Portfolio Combination","text":"<p>In counterparty credit risk (CCR), thousands of trades sharing common risk factors must be priced at millions of Monte Carlo scenarios.  Building a Chebyshev proxy per trade reduces pricing cost, but evaluating 1,000 separate proxies at each scenario is still \\(O(\\text{num\\_trades})\\).</p> <p>Algebraic combination lets you pre-combine trade proxies into a single netting-set-level proxy:</p> <pre><code>portfolio = w1 * trade_1 + w2 * trade_2 + ... + wn * trade_n\n</code></pre> <p>One evaluation of <code>portfolio</code> gives the netting set price -- \\(O(1)\\) regardless of the number of trades.</p> <p>When to use algebra</p> <p>Use algebraic combination when multiple Chebyshev interpolants share the same grid (same domain, node counts, derivative order) and you want to combine them into a single interpolant for faster evaluation.</p> <p>If your interpolants live on different sets of dimensions (e.g., Trade A depends on (spot, rate) while Trade B depends on (spot, vol)), use Extrusion &amp; Slicing to bring them onto a common grid first.</p>"},{"location":"user-guide/algebra/#mathematical-basis","title":"Mathematical Basis","text":"<p>The barycentric interpolation formula evaluates a Chebyshev Tensor (CT) at any point \\(\\mathbf{x}\\):</p> \\[ p_n(\\mathbf{x}) = \\sum_{i_1, \\ldots, i_d} v_{i_1, \\ldots, i_d} \\prod_{k=1}^{d} \\ell^{(k)}_{i_k}(x_k) \\] <p>where \\(\\ell^{(k)}_{i_k}\\) are the barycentric basis functions.  This is linear in the values \\(v_{i_1, \\ldots, i_d}\\).</p> <p>Theorem (Linearity of CT operations).  Let \\(T_f\\) and \\(T_g\\) be two CTs on the same grid.  Then:</p> <ol> <li>Addition: \\(T_f + T_g\\) (element-wise on grid values) is the CT for \\(f + g\\)</li> <li>Scalar multiplication: \\(c \\cdot T_f\\) is the CT for \\(c \\cdot f\\)</li> <li>Subtraction: \\(T_f - T_g\\) is the CT for \\(f - g\\)</li> </ol> <p>Proof.  Direct from linearity of the barycentric formula.</p> <p>Corollary (Derivatives).  Since the spectral differentiation matrix \\(\\mathcal{D}_k\\) depends only on grid points:</p> \\[ \\mathcal{D}_k (v_f + v_g) = \\mathcal{D}_k v_f + \\mathcal{D}_k v_g \\] <p>Derivatives of a combined CT equal the combined derivatives.</p> <p>Error bound.  By the triangle inequality:</p> \\[ \\|(f + g) - (p_f + p_g)\\|_\\infty \\leq \\epsilon_f + \\epsilon_g \\] <p>For scalar multiplication: \\(\\|cf - cp_f\\|_\\infty = |c| \\cdot \\epsilon_f\\).</p> <p>Book reference</p> <p>The linearity of Chebyshev Tensor operations is described in Section 3.9 of Ruiz &amp; Zeron (2021), Machine Learning for Risk Calculations, Wiley Finance.</p>"},{"location":"user-guide/algebra/#quick-start","title":"Quick Start","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\n# Two functions on the same grid\ndef f(x, _):\n    return math.sin(x[0]) + math.sin(x[1])\n\ndef g(x, _):\n    return math.cos(x[0]) * math.cos(x[1])\n\na = ChebyshevApproximation(f, 2, [[-1, 1], [-1, 1]], [11, 11])\nb = ChebyshevApproximation(g, 2, [[-1, 1], [-1, 1]], [11, 11])\na.build(); b.build()\n\n# Combine into a portfolio proxy\nportfolio = 0.6 * a + 0.4 * b\n\n# Evaluate price and Greeks at any point\npoint = [0.5, 0.3]\nprice = portfolio.vectorized_eval(point, [0, 0])\ndelta = portfolio.vectorized_eval(point, [1, 0])\ngamma = portfolio.vectorized_eval(point, [2, 0])\n\nprint(portfolio)\n</code></pre> <p>Output:</p> <pre><code>ChebyshevApproximation (2D, built)\n  Nodes:       [11, 11] (121 total)\n  Domain:      [-1, 1] x [-1, 1]\n  Build:       0.000s, 0 evaluations\n  Error est:   4.22e-10\n  Derivatives: up to order 2\n</code></pre> <p>The combined <code>portfolio</code> is a regular <code>ChebyshevApproximation</code> -- all existing evaluation methods (<code>eval</code>, <code>vectorized_eval</code>, <code>vectorized_eval_multi</code>, <code>vectorized_eval_batch</code>) work unchanged.</p>"},{"location":"user-guide/algebra/#supported-operations","title":"Supported Operations","text":"Operator Example Result <code>+</code> <code>cheb_a + cheb_b</code> Element-wise add tensor values <code>-</code> <code>cheb_a - cheb_b</code> Element-wise subtract <code>*</code> scalar <code>3.0 * cheb</code> or <code>cheb * 3.0</code> Scale all tensor values <code>/</code> scalar <code>cheb / 2.0</code> Divide all tensor values unary <code>-</code> <code>-cheb</code> Negate all tensor values <code>+=</code> <code>cheb_a += cheb_b</code> In-place add <code>-=</code> <code>cheb_a -= cheb_b</code> In-place subtract <code>*=</code> <code>cheb *= 3.0</code> In-place scale <code>/=</code> <code>cheb /= 2.0</code> In-place divide"},{"location":"user-guide/algebra/#compatibility-requirements","title":"Compatibility Requirements","text":"<p>Both operands must share:</p> <ul> <li>Same type -- both <code>ChebyshevApproximation</code>, both <code>ChebyshevSpline</code>, etc.</li> <li>Same <code>num_dimensions</code> -- number of interpolation dimensions</li> <li>Same <code>domain</code> -- identical domain bounds in every dimension</li> <li>Same <code>n_nodes</code> -- same node counts in every dimension</li> <li>Same <code>max_derivative_order</code> -- same spectral differentiation depth</li> <li>Both must be built -- <code>build()</code> must have been called on each operand</li> </ul> <p>Additional requirements for specific classes:</p> <ul> <li><code>ChebyshevSpline</code>: same <code>knots</code> in every dimension</li> <li><code>ChebyshevSlider</code>: same <code>partition</code> and same <code>pivot_point</code></li> </ul> <p>A <code>ValueError</code> is raised if any of these conditions are not met.</p> <p>Checking compatibility</p> <pre><code># These will raise ValueError:\na = ChebyshevApproximation(f, 2, [[0, 1], [0, 1]], [10, 10])\nb = ChebyshevApproximation(g, 2, [[0, 1], [0, 2]], [10, 10])  # different domain\na.build(); b.build()\nc = a + b  # ValueError: domain mismatch\n</code></pre>"},{"location":"user-guide/algebra/#derivatives","title":"Derivatives","text":"<p>Derivatives propagate automatically through algebraic operations.  The combined interpolant inherits the spectral differentiation matrices from its operands, so no re-computation is needed:</p> <pre><code># Build two interpolants\ncall.build()\nput.build()\n\n# Combine\nportfolio = 0.6 * call + 0.4 * put\n\n# Delta of the portfolio = 0.6 * delta_call + 0.4 * delta_put\ndelta = portfolio.vectorized_eval(point, [1, 0, 0])\n\n# Gamma works too\ngamma = portfolio.vectorized_eval(point, [2, 0, 0])\n</code></pre> <p>This follows directly from the linearity of the spectral differentiation matrices \\(\\mathcal{D}_k\\).</p>"},{"location":"user-guide/algebra/#error-estimation","title":"Error Estimation","text":"<p><code>error_estimate()</code> recomputes from the combined Chebyshev coefficients (DCT of the combined tensor values).  In practice this may give a tighter bound than the triangle inequality \\(\\epsilon_f + \\epsilon_g\\), because cancellation between the high-order coefficients of \\(f\\) and \\(g\\) can reduce the estimated tail.</p> <pre><code>portfolio = 0.6 * call + 0.4 * put\nerr = portfolio.error_estimate()\nprint(f\"Portfolio error estimate: {err:.2e}\")\n</code></pre>"},{"location":"user-guide/algebra/#serialization","title":"Serialization","text":"<p>Combined interpolants support <code>save()</code> and <code>load()</code> just like any other built interpolant.  The underlying function reference is lost (<code>function=None</code>), but all tensor values, grid data, and differentiation matrices are preserved:</p> <pre><code>portfolio = 0.6 * call + 0.4 * put\nportfolio.save(\"portfolio.pkl\")\n\nloaded = ChebyshevApproximation.load(\"portfolio.pkl\")\nloaded.vectorized_eval(point, [0, 0])  # works identically\n</code></pre>"},{"location":"user-guide/algebra/#spline-and-slider-examples","title":"Spline and Slider Examples","text":""},{"location":"user-guide/algebra/#chebyshevspline-addition","title":"ChebyshevSpline addition","text":"<p>Two splines with the same knots can be combined:</p> <pre><code>from pychebyshev import ChebyshevSpline\n\nspline_a = ChebyshevSpline(\n    f, 2, [[80, 120], [0.25, 1.0]], [15, 15],\n    knots=[[100.0], []],\n)\nspline_b = ChebyshevSpline(\n    g, 2, [[80, 120], [0.25, 1.0]], [15, 15],\n    knots=[[100.0], []],\n)\nspline_a.build(); spline_b.build()\n\ncombined = spline_a + spline_b\nprice = combined.eval([110.0, 0.5], [0, 0])\n</code></pre> <p>Each piece is combined independently -- the combined spline has the same knot structure as its operands.</p>"},{"location":"user-guide/algebra/#chebyshevslider-addition","title":"ChebyshevSlider addition","text":"<p>Two sliders with the same partition and pivot point can be combined:</p> <pre><code>from pychebyshev import ChebyshevSlider\n\nslider_a = ChebyshevSlider(\n    f, 5, domain, [11] * 5,\n    partition=[[0, 1], [2, 3, 4]],\n    pivot_point=[0.0] * 5,\n)\nslider_b = ChebyshevSlider(\n    g, 5, domain, [11] * 5,\n    partition=[[0, 1], [2, 3, 4]],\n    pivot_point=[0.0] * 5,\n)\nslider_a.build(); slider_b.build()\n\ncombined = slider_a + slider_b\nval = combined.eval([0.5] * 5, [0] * 5)\n</code></pre> <p>Each slide is combined independently, preserving the additive decomposition structure.</p>"},{"location":"user-guide/algebra/#why-pointwise-products-are-not-supported","title":"Why Pointwise Products are NOT Supported","text":"<p>The product \\(f \\cdot g\\) is not \\(v_f \\odot v_g\\) (element-wise product of grid values).  The product of two polynomials of degree \\(n\\) has degree \\(2n\\), which cannot be represented on the same \\(n\\)-point grid.</p> <p>Only linear combinations (addition, subtraction, scalar multiplication) are exact on the same grid.  Pointwise multiplication of two Chebyshev interpolants requires a grid refinement step and is not supported.</p> <p>Workaround for products</p> <p>If you need to approximate \\(f \\cdot g\\), build a single Chebyshev interpolant for the product function directly: define <code>h(x, aux) = f(x) * g(x)</code> and call <code>ChebyshevApproximation(h, ...).build()</code>.</p>"},{"location":"user-guide/algebra/#limitations","title":"Limitations","text":"<ul> <li>No <code>ChebyshevTT</code> operators -- TT addition requires rank control (rank of   \\(T_f + T_g\\) is \\(r_f + r_g\\)) and is not currently implemented.</li> <li>No cross-type operations -- you cannot add a <code>ChebyshevApproximation</code> to a   <code>ChebyshevSpline</code> or a <code>ChebyshevSlider</code>.</li> <li>Operands must share exact grid parameters -- domain, node counts, derivative   order, and (where applicable) knots or partition must be identical.</li> <li>Result has <code>function=None</code> -- the combined interpolant cannot call <code>build()</code>   again, since it has no underlying function reference.</li> </ul>"},{"location":"user-guide/calculus/","title":"Chebyshev Calculus","text":""},{"location":"user-guide/calculus/#motivation","title":"Motivation","text":"<p>Once you have a Chebyshev interpolant, you can compute integrals, find roots, and optimize -- all without re-evaluating the original (expensive) function. These operations work directly on the stored tensor values using spectral methods:</p> <ul> <li>Integration via Fej\u00e9r-1 quadrature weights (DCT-III)</li> <li>Rootfinding via companion matrix eigenvalues</li> <li>Optimization via derivative rootfinding + endpoint evaluation</li> </ul> <p>The key insight is that the Chebyshev interpolant is a polynomial, and polynomial integrals, roots, and extrema can be computed exactly from the expansion coefficients -- no additional function evaluations needed.</p> <p>In quantitative finance, this enables computing expected exposures (\\(\\mathbb{E}[\\max(V, 0)]\\) via integration), finding break-even levels (roots of \\(V - K\\)), and locating worst-case scenarios (optimization) -- all from a single pre-built proxy, without calling the pricing engine again.</p> <p>Cross-reference</p> <p>See Chebyshev Algebra for combining interpolants and Extrusion &amp; Slicing for dimension manipulation.</p>"},{"location":"user-guide/calculus/#supported-classes","title":"Supported Classes","text":"Class <code>integrate()</code> <code>roots()</code> <code>minimize()</code> / <code>maximize()</code> <code>ChebyshevApproximation</code> Yes Yes Yes <code>ChebyshevSpline</code> Yes Yes Yes <code>ChebyshevSlider</code> No No No <code>ChebyshevTT</code> No No No"},{"location":"user-guide/calculus/#integration","title":"Integration","text":""},{"location":"user-guide/calculus/#theory","title":"Theory","text":"<p>Given a Chebyshev interpolant \\(p_n(x) = \\sum_{k=0}^{n-1} c_k T_k(x)\\) on \\([-1, 1]\\), the definite integral is:</p> \\[ \\int_{-1}^{1} p_n(x)\\, dx = 2\\,c_0 + \\sum_{\\substack{k=2 \\\\ k \\text{ even}}}^{n-1} \\frac{2\\,c_k}{1 - k^2} \\] <p>since \\(\\int_{-1}^{1} T_k(x)\\,dx = 2/(1-k^2)\\) for even \\(k\\) and \\(0\\) for odd \\(k\\).</p> <p>This is exact for the polynomial interpolant -- the only error is from the original Chebyshev approximation, not from the quadrature.</p> <p>In practice, we compute Fej\u00e9r-1 quadrature weights \\(w_j\\) such that:</p> \\[ \\int_{-1}^{1} p(x)\\, dx = \\sum_{j=0}^{n-1} w_j \\, p(x_j) \\] <p>where \\(x_j\\) are the Chebyshev Type I nodes.  The weights are computed in \\(O(n \\log n)\\) via the DCT-III algorithm of Waldvogel (2006):</p> \\[ w_j = \\frac{1}{n}\\left[I_0 + 2\\sum_{k=1}^{n-1} I_k \\cos\\!\\left(\\frac{\\pi\\, k\\,(2j+1)}{2n}\\right)\\right], \\quad I_k = \\begin{cases} \\frac{2}{1-k^2} &amp; k \\text{ even} \\\\ 0 &amp; k \\text{ odd} \\end{cases} \\] <p>The vector \\([I_0, I_1, \\ldots, I_{n-1}]\\) is the input to a DCT-III, giving all \\(n\\) weights in a single \\(O(n \\log n)\\) transform.</p> <p>Domain scaling. For a general interval \\([a, b]\\):</p> \\[ \\int_a^b f(x)\\, dx \\approx \\frac{b - a}{2} \\sum_{j=0}^{n-1} w_j \\, v_j \\] <p>where \\(v_j\\) are the stored tensor values at the Chebyshev nodes.</p> <p>Multi-dimensional integration. For a \\(d\\)-dimensional interpolant, integration along each dimension is a tensor contraction via <code>np.tensordot</code> (routed through BLAS GEMV):</p> \\[ \\int_{\\Omega} p(\\mathbf{x})\\, d\\mathbf{x} = \\sum_{i_1,\\ldots,i_d} v_{i_1,\\ldots,i_d} \\prod_{k=1}^{d} w_{i_k}^{(k)} \\cdot s_k \\] <p>where \\(s_k = (b_k - a_k)/2\\) is the half-width of dimension \\(k\\).</p>"},{"location":"user-guide/calculus/#usage","title":"Usage","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\ndef f(x, _):\n    return math.sin(x[0]) * math.cos(x[1])\n\ncheb = ChebyshevApproximation(f, 2, [[-1, 1], [-1, 1]], [11, 11])\ncheb.build()\n\n# Full integral over all dimensions -&gt; float\ntotal = cheb.integrate()\n\n# Partial integral -- integrate out dim 1, get 1D interpolant\ncheb_1d = cheb.integrate(dims=[1])\nvalue = cheb_1d.vectorized_eval([0.5], [0])\n\n# Integrate multiple dimensions at once\ncheb_3d = ChebyshevApproximation(h, 3, domains, n_nodes)\ncheb_3d.build()\ncheb_1d = cheb_3d.integrate(dims=[0, 2])\n</code></pre>"},{"location":"user-guide/calculus/#integrate-api","title":"<code>integrate()</code> API","text":"Parameter Type Description <code>dims</code> <code>int</code>, <code>list[int]</code>, or <code>None</code> Dimensions to integrate out. <code>None</code> = all. <p>Returns: <code>float</code> if all dimensions are integrated; otherwise a lower-dimensional interpolant of the same type (<code>ChebyshevApproximation</code> or <code>ChebyshevSpline</code>).</p> <p>Errors:</p> <ul> <li><code>RuntimeError</code> if <code>build()</code> has not been called</li> <li><code>ValueError</code> if any dimension index is out of range or duplicated</li> </ul>"},{"location":"user-guide/calculus/#rootfinding","title":"Rootfinding","text":""},{"location":"user-guide/calculus/#theory_1","title":"Theory","text":"<p>Roots of a Chebyshev interpolant are found via the colleague matrix (Good 1961), a Chebyshev analogue of the companion matrix.  Given the expansion \\(p_n(x) = \\sum_{k=0}^{n-1} c_k T_k(x)\\), the roots of \\(p_n\\) are the eigenvalues of an \\((n-1) \\times (n-1)\\) tridiagonal-plus-rank-1 matrix.</p> <p>PyChebyshev delegates to <code>numpy.polynomial.chebyshev.chebroots()</code>, which constructs this colleague matrix and computes eigenvalues via LAPACK QR. Complex and out-of-domain roots are filtered out, and the remaining real roots are mapped from \\([-1, 1]\\) to the physical domain \\([a, b]\\).</p> <p>For multi-dimensional interpolants, the interpolant is first sliced to 1-D using the existing <code>slice()</code> infrastructure (see Extrusion &amp; Slicing), then rootfinding proceeds on the resulting 1-D polynomial.</p>"},{"location":"user-guide/calculus/#usage_1","title":"Usage","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\n# 1D roots\ncheb = ChebyshevApproximation(lambda x, _: math.sin(x[0]), 1, [[-4, 4]], [25])\ncheb.build()\nroots = cheb.roots()  # array([-pi, 0, pi])\n\n# Multi-D: fix other dims, find roots along dim 0\ncheb_2d = ChebyshevApproximation(\n    lambda x, _: math.sin(x[0]) * math.cos(x[1]),\n    2, [[-4, 4], [-2, 2]], [25, 15],\n)\ncheb_2d.build()\nroots = cheb_2d.roots(dim=0, fixed={1: 0.5})\n</code></pre>"},{"location":"user-guide/calculus/#roots-api","title":"<code>roots()</code> API","text":"Parameter Type Description <code>dim</code> <code>int</code> or <code>None</code> Dimension along which to find roots. Defaults to <code>0</code> for 1-D. <code>fixed</code> <code>dict</code> or <code>None</code> For multi-D: <code>{dim_index: value}</code> for all dimensions except <code>dim</code>. <p>Returns: Sorted <code>ndarray</code> of root locations in the physical domain.</p> <p>Errors:</p> <ul> <li><code>RuntimeError</code> if <code>build()</code> has not been called</li> <li><code>ValueError</code> if <code>dim</code> is out of range, <code>fixed</code> is incomplete (missing   dimensions), or a fixed value is outside its domain</li> </ul>"},{"location":"user-guide/calculus/#optimization","title":"Optimization","text":""},{"location":"user-guide/calculus/#theory_2","title":"Theory","text":"<p>Minima and maxima of a polynomial on a closed interval occur either at critical points (where the derivative is zero) or at the endpoints. PyChebyshev:</p> <ol> <li>Computes derivative values at the Chebyshev nodes via the spectral    differentiation matrix \\(\\mathcal{D}\\) (Berrut &amp; Trefethen 2004)</li> <li>Finds all roots of the derivative via the colleague matrix (critical points)</li> <li>Evaluates the original interpolant at all critical points and domain endpoints</li> <li>Returns the global minimum or maximum</li> </ol> <p>For multi-dimensional interpolants, the interpolant is first sliced to 1-D (same as rootfinding), then optimization proceeds on the 1-D polynomial.</p>"},{"location":"user-guide/calculus/#usage_2","title":"Usage","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\ncheb = ChebyshevApproximation(lambda x, _: math.sin(x[0]), 1, [[-4, 4]], [25])\ncheb.build()\n\nval, loc = cheb.minimize()   # (-1.0, -pi/2)\nval, loc = cheb.maximize()   # (1.0, pi/2)\n\n# Multi-D: fix other dims\ncheb_2d = ChebyshevApproximation(\n    lambda x, _: x[0] ** 2 + x[1],\n    2, [[-1, 1], [-1, 1]], [11, 11],\n)\ncheb_2d.build()\nval, loc = cheb_2d.minimize(dim=0, fixed={1: 0.5})  # (0.5, 0.0)\n</code></pre>"},{"location":"user-guide/calculus/#minimize-maximize-api","title":"<code>minimize()</code> / <code>maximize()</code> API","text":"Parameter Type Description <code>dim</code> <code>int</code> or <code>None</code> Dimension along which to optimize. Defaults to <code>0</code> for 1-D. <code>fixed</code> <code>dict</code> or <code>None</code> For multi-D: <code>{dim_index: value}</code> for all dimensions except <code>dim</code>. <p>Returns: <code>(value, location)</code> tuple of two <code>float</code>s -- the optimal value and its coordinate in the target dimension.</p> <p>Errors:</p> <ul> <li><code>RuntimeError</code> if <code>build()</code> has not been called</li> <li><code>ValueError</code> if <code>dim</code> is out of range, <code>fixed</code> is incomplete, or a fixed   value is outside its domain</li> </ul>"},{"location":"user-guide/calculus/#spline-support","title":"Spline Support","text":"<p>All three calculus operations are supported on <code>ChebyshevSpline</code>:</p> <ul> <li>Integration: sums the integrals of each piece (pieces cover disjoint   sub-domains). Partial integration sums piece contributions along the   integrated dimension and returns a lower-dimensional spline.</li> <li>Roots: finds roots in each piece independently, then merges and   deduplicates at knot boundaries.</li> <li>Optimization: computes per-piece extrema and returns the global   minimum or maximum across all pieces.</li> </ul> <pre><code>from pychebyshev import ChebyshevSpline\n\nspline = ChebyshevSpline(\n    lambda x, _: abs(x[0]) - 0.3,\n    1, [[-1, 1]], [15], [[0.0]],\n)\nspline.build()\n\nintegral = spline.integrate()\nroots = spline.roots()          # array([-0.3, 0.3])\nval, loc = spline.minimize()    # (-0.3, 0.0)\n</code></pre> <p>The API signatures and return types are identical to <code>ChebyshevApproximation</code>. Partial integration on a spline returns a lower-dimensional <code>ChebyshevSpline</code>.</p>"},{"location":"user-guide/calculus/#derivatives-error-estimation-and-serialization","title":"Derivatives, Error Estimation, and Serialization","text":"<p>Partial integration returns a fully functional interpolant (either <code>ChebyshevApproximation</code> or <code>ChebyshevSpline</code>).  All existing features work on the result:</p> <ul> <li>Derivatives: <code>vectorized_eval(point, [1])</code> computes derivatives in   the surviving dimensions via the spectral differentiation matrices.</li> <li>Error estimation: <code>error_estimate()</code> recomputes from the DCT   coefficients of the reduced tensor.</li> <li>Serialization: <code>save()</code> and <code>load()</code> work as usual.</li> <li>Further calculus: you can call <code>integrate()</code>, <code>roots()</code>,   <code>minimize()</code>, or <code>maximize()</code> on the result.</li> </ul> <pre><code># Partial integrate, then take derivatives and estimate error\ncheb_2d = ChebyshevApproximation(f, 2, [[-1, 1], [-1, 1]], [15, 15])\ncheb_2d.build()\n\ncheb_1d = cheb_2d.integrate(dims=[0])\nderiv = cheb_1d.vectorized_eval([0.5], [1])\nerr = cheb_1d.error_estimate()\ncheb_1d.save(\"partial_integral.pkl\")\n</code></pre> <p><code>roots()</code>, <code>minimize()</code>, and <code>maximize()</code> return scalar values (arrays or tuples), so derivatives/serialization are not applicable to their outputs.</p>"},{"location":"user-guide/calculus/#performance","title":"Performance","text":"Operation Complexity Notes Fej\u00e9r-1 weights \\(O(n \\log n)\\) DCT-III (Waldvogel 2006), computed once per dimension 1-D integration \\(O(n)\\) Dot product of weights and values Multi-D integration \\(O(n^d)\\) Sequential <code>np.tensordot</code> contractions (BLAS GEMV) 1-D rootfinding \\(O(n^3)\\) Companion matrix eigenvalues (LAPACK QR) 1-D optimization \\(O(n^3)\\) Derivative roots + endpoint evaluation <p>For typical node counts (\\(n \\leq 50\\)), the \\(O(n^3)\\) companion matrix eigenvalue computation is negligible (sub-millisecond). All operations reuse existing infrastructure: DCT coefficients, spectral differentiation matrices, and barycentric evaluation.</p>"},{"location":"user-guide/calculus/#limitations","title":"Limitations","text":"<ul> <li>Not yet supported on <code>ChebyshevSlider</code> or <code>ChebyshevTT</code>.   Calculus on Tensor Train interpolants would require TT-specific   coefficient extraction; slider calculus would need per-slide integration   with additive recombination.</li> <li>Sub-interval integration (partial domain bounds) is deferred to a   future version. Currently, <code>integrate()</code> integrates over the full domain   of each dimension.</li> <li>Multi-D rootfinding (2D Bezout resultants) is not implemented. Only   1-D slices are supported via the <code>dim</code> + <code>fixed</code> interface.</li> <li>Result has <code>function=None</code> -- partial integration results cannot call   <code>build()</code> again, since there is no underlying function reference.</li> </ul>"},{"location":"user-guide/calculus/#references","title":"References","text":"<ol> <li> <p>Waldvogel, J. (2006), \"Fast Construction of the Fej\u00e9r and    Clenshaw--Curtis Quadrature Rules\", BIT Numerical Mathematics    46(2):195--202.</p> </li> <li> <p>Trefethen, L.N. (2013), Approximation Theory and Approximation    Practice, SIAM, Chapters 18--21.</p> </li> <li> <p>Good, I.J. (1961), \"The colleague matrix, a Chebyshev analogue of the    companion matrix\", Quarterly Journal of Mechanics and Applied    Mathematics 14:195--196.</p> </li> <li> <p>Berrut, J.-P. &amp; Trefethen, L.N. (2004), \"Barycentric Lagrange    Interpolation\", SIAM Review 46(3):501--517.</p> </li> </ol>"},{"location":"user-guide/concepts/","title":"Mathematical Concepts","text":""},{"location":"user-guide/concepts/#why-chebyshev-interpolation","title":"Why Chebyshev Interpolation?","text":"<p>Polynomial interpolation with equally-spaced points suffers from Runge's phenomenon \u2014 wild oscillations near interval endpoints that worsen as polynomial degree increases. Chebyshev nodes solve this by clustering near boundaries:</p> \\[x_i = \\cos\\left(\\frac{(2i-1)\\pi}{2n}\\right), \\quad i = 1, \\ldots, n\\] <p>The Lebesgue constant for Chebyshev nodes grows only logarithmically: \\(\\Lambda_n \\leq \\frac{2}{\\pi}\\log(n+1) + 1\\), versus exponential growth for equidistant points.</p>"},{"location":"user-guide/concepts/#spectral-convergence","title":"Spectral Convergence","text":"<p>For functions analytic in a Bernstein ellipse with parameter \\(\\rho &gt; 1\\), the interpolation error decays exponentially:</p> \\[|f(x) - p_N(x)| = O(\\rho^{-N})\\] <p>Each additional node multiplies accuracy by a constant factor \\(\\rho\\).</p>"},{"location":"user-guide/concepts/#bernstein-ellipse","title":"Bernstein ellipse","text":"<p>A Bernstein ellipse is an ellipse in the complex plane with foci at \\(x = -1\\) and \\(x = +1\\). The parameter \\(\\rho\\) equals the sum of the semi-major and semi-minor axis lengths. Functions analytic inside a larger ellipse (larger \\(\\rho\\)) converge faster.</p> <p>Practical implication: The convergence rate depends on how far the function's nearest singularity (pole, branch cut, discontinuity) is from the real interval \\([-1, 1]\\) in the complex plane. For example:</p> <ul> <li>\\(f(x) = e^x\\) is entire (no singularities) -- \\(\\rho = \\infty\\), superexponential convergence.</li> <li>\\(f(x) = 1/(1 + 25x^2)\\) has poles at \\(x = \\pm i/5\\) -- the Bernstein ellipse must   avoid these poles, limiting \\(\\rho\\) and slowing convergence.</li> <li>Black-Scholes option prices are analytic in all parameters over typical domains,   giving large \\(\\rho\\) and rapid convergence with 10--15 nodes per dimension.</li> </ul> <p>For the full theory, see Trefethen, Approximation Theory and Approximation Practice, SIAM 2019, Chapter 8.</p>"},{"location":"user-guide/concepts/#barycentric-interpolation-formula","title":"Barycentric Interpolation Formula","text":"<p>The interpolating polynomial is expressed as:</p> \\[p(x) = \\frac{\\sum_{i=0}^{n} \\frac{w_i f_i}{x - x_i}}{\\sum_{i=0}^{n} \\frac{w_i}{x - x_i}}\\] <p>where the barycentric weights \\(w_i = 1 / \\prod_{j \\neq i}(x_i - x_j)\\) depend only on node positions, not on function values. This enables full pre-computation.</p>"},{"location":"user-guide/concepts/#multi-dimensional-extension","title":"Multi-Dimensional Extension","text":"<p>For a \\(d\\)-dimensional function, PyChebyshev uses dimensional decomposition:</p> <ol> <li>Start with the full tensor of function values at all node combinations</li> <li>Contract one dimension at a time using barycentric interpolation</li> <li>Each contraction reduces dimensionality by 1 (5D \u2192 4D \u2192 ... \u2192 scalar)</li> </ol> <p>This avoids the curse of dimensionality in the evaluation step \u2014 query cost scales linearly with the number of dimensions.</p>"},{"location":"user-guide/concepts/#analytical-derivatives","title":"Analytical Derivatives","text":"<p>Derivatives are computed using spectral differentiation matrices \\(D^{(k)}\\):</p> \\[D^{(1)}_{ij} = \\frac{w_j / w_i}{x_i - x_j} \\quad (i \\neq j), \\qquad D^{(1)}_{ii} = -\\sum_{k \\neq i} D^{(1)}_{ik}\\] <p>Given function values \\(\\mathbf{f}\\) at nodes, \\(D^{(1)} \\mathbf{f}\\) gives exact derivative values at those same nodes. These derivative values are then interpolated to the query point using the barycentric formula.</p>"},{"location":"user-guide/error-estimation/","title":"Error Estimation","text":""},{"location":"user-guide/error-estimation/#introduction","title":"Introduction","text":"<p>After building a Chebyshev interpolant, you often want to know how accurate it is without comparing against the true function at thousands of test points. <code>error_estimate()</code> provides an ex ante estimate of the interpolation error using only the Chebyshev coefficients already computed during the build step.</p> <p>This is useful for:</p> <ul> <li>Validating node counts -- check whether your grid is fine enough before deploying.</li> <li>Adaptive refinement -- increase nodes in dimensions where the error is large.</li> <li>Confidence reporting -- attach an approximate error magnitude to interpolated values.</li> </ul>"},{"location":"user-guide/error-estimation/#quick-start","title":"Quick Start","text":"<pre><code>from pychebyshev import ChebyshevApproximation\nimport math\n\ndef f(x, _):\n    return math.sin(x[0]) * math.cos(x[1])\n\ncheb = ChebyshevApproximation(f, 2, [[-1, 1], [-1, 1]], [15, 15])\ncheb.build(verbose=False)\nprint(f\"Error estimate: {cheb.error_estimate():.2e}\")\n</code></pre> <p>No extra function evaluations are needed -- the estimate is computed from the tensor of function values that <code>build()</code> already stored.</p>"},{"location":"user-guide/error-estimation/#mathematical-background","title":"Mathematical Background","text":""},{"location":"user-guide/error-estimation/#chebyshev-series-expansion","title":"Chebyshev series expansion","text":"<p>Any sufficiently smooth function on \\([-1, 1]\\) can be expanded in Chebyshev polynomials:</p> \\[f(x) = \\sum_{k=0}^{\\infty} c_k\\, T_k(x)\\] <p>where \\(T_k\\) is the Chebyshev polynomial of the first kind of degree \\(k\\), and \\(c_k\\) are the expansion coefficients. When we interpolate with \\(n\\) nodes, we compute a degree-\\((n-1)\\) polynomial that implicitly truncates this series:</p> \\[p_n(x) = \\sum_{k=0}^{n-1} \\hat{c}_k\\, T_k(x)\\] <p>The interpolation error \\(f(x) - p_n(x)\\) comes from two sources: (1) the omitted high-degree terms \\(c_n, c_{n+1}, \\ldots\\) and (2) aliasing, where these omitted terms fold back onto the computed coefficients. For well-resolved functions, both sources are small when the trailing coefficients are small.</p>"},{"location":"user-guide/error-estimation/#why-the-last-coefficient-estimates-the-error","title":"Why the last coefficient estimates the error","text":"<p>For a function analytic in a Bernstein ellipse with parameter \\(\\rho &gt; 1\\) (see Mathematical Concepts), the Chebyshev coefficients satisfy \\(|c_k| = O(\\rho^{-k})\\). This means each successive coefficient is roughly \\(\\rho\\) times smaller than the previous one. The last included coefficient \\(|c_{n-1}|\\) is therefore:</p> <ol> <li> <p>An upper bound on the omitted tail. Since \\(|c_k| \\leq M \\rho^{-k}\\) and the    tail sum \\(\\sum_{k=n}^{\\infty} |c_k|\\) is a geometric series with ratio    \\(\\rho^{-1} &lt; 1\\), we have    \\(\\sum_{k=n}^{\\infty} |c_k| \\lesssim |c_{n-1}| / (\\rho - 1)\\). When    \\(\\rho\\) is even moderately large (say, \\(\\rho &gt; 2\\)), the omitted tail is    comparable in magnitude to \\(|c_{n-1}|\\) itself.</p> </li> <li> <p>A proxy for aliasing error. The aliased contributions (omitted terms folding    onto lower coefficients) are bounded by the same geometric decay, so they are also    \\(O(|c_{n-1}|)\\) for well-resolved functions.</p> </li> </ol> <p>The practical rule: if \\(|c_{n-1}|\\) is small, both the truncation and aliasing errors are small, and the interpolant is well-converged.</p> <p>Heuristic, not a formal bound</p> <p>This estimate is an empirically reliable proxy, not a rigorous upper bound. Ruiz &amp; Zeron (2021, Section 3.4) report that they have never encountered a real-world case where small trailing coefficients failed to indicate convergence. However, pathological functions (e.g., those with singularities just outside the Bernstein ellipse) could have slowly decaying coefficients that make the estimate optimistic. Always validate against known solutions when possible.</p>"},{"location":"user-guide/error-estimation/#computing-coefficients-via-dct-ii","title":"Computing coefficients via DCT-II","text":"<p>PyChebyshev uses Type I Chebyshev nodes (roots of \\(T_n\\), also called Gauss--Chebyshev nodes):</p> \\[x_i = \\cos\\!\\left(\\frac{(2i - 1)\\,\\pi}{2n}\\right), \\quad i = 1, \\ldots, n\\] <p>For values sampled at these \\(n\\) nodes, the Chebyshev expansion coefficients \\(c_k\\) can be recovered exactly via the Discrete Cosine Transform (DCT-II).</p> <p>Why DCT-II works. The connection comes from the orthogonality of Chebyshev polynomials. Evaluating \\(T_k(x_i)\\) at the Type I nodes and exploiting the identity \\(T_k(\\cos\\theta) = \\cos(k\\theta)\\) turns the coefficient formula into a discrete cosine sum -- precisely the DCT-II. The computation runs in \\(O(n \\log n)\\) via FFT.</p> <p>In practice, the implementation:</p> <ol> <li>Reverses the node-order values (<code>::-1</code>) because <code>scipy.fft.dct</code> expects a    specific ordering convention, while PyChebyshev stores nodes in ascending order.</li> <li>Divides by \\(n\\) (the normalization factor for the DCT-II).</li> <li>Halves the zeroth coefficient (\\(c_0 \\mathrel{/}= 2\\)) because the Chebyshev    series convention uses \\(\\frac{c_0}{2} T_0(x) + c_1 T_1(x) + \\cdots\\), while the    raw DCT includes the full \\(c_0\\).</li> </ol>"},{"location":"user-guide/error-estimation/#reference","title":"Reference","text":"<p>This error estimation approach follows the ex ante method described in Ruiz &amp; Zeron, Machine Learning for Risk Calculations, Wiley Finance, 2021, Section 3.4.</p>"},{"location":"user-guide/error-estimation/#multi-dimensional-error","title":"Multi-Dimensional Error","text":"<p>For a \\(D\\)-dimensional interpolant on a tensor grid with \\(n_d\\) nodes in dimension \\(d\\), the error estimate generalizes as follows:</p> <ol> <li>Extract 1-D slices. For each dimension \\(d\\), fix all other indices and extract    every 1-D slice of the tensor along dimension \\(d\\).</li> <li>Compute per-slice error. For each slice, compute the Chebyshev coefficients    via DCT-II and take the magnitude of the last coefficient \\(|c_{n_d - 1}|\\).</li> <li>Maximize over slices. Take the maximum \\(|c_{n_d - 1}|\\) across all slices for    dimension \\(d\\). This worst-case slice represents the hardest-to-approximate 1-D    cross-section of the function along that axis.</li> <li>Sum across dimensions. The total error estimate is the sum of per-dimension    maxima:</li> </ol> \\[\\hat{E} = \\sum_{d=1}^{D} \\max_{\\text{slices along } d} |c_{n_d - 1}|\\] <p>Why sum across dimensions? PyChebyshev evaluates a multi-dimensional interpolant via dimensional decomposition -- contracting one axis at a time (see Multi-Dimensional Extension). At each contraction step, the 1-D interpolation error for that dimension is injected into the remaining computation. In the worst case, these per-dimension errors add up. The summation therefore represents a conservative heuristic: the total error is at most the sum of the worst per-dimension errors, assuming the errors do not cancel.</p> <p>Not a tight bound</p> <p>In practice, \\(\\hat{E}\\) is often pessimistic because: (a) the worst-case slice rarely coincides across all other index combinations, and (b) errors from different dimensions tend to partially cancel rather than align. The estimate is best used as an order-of-magnitude indicator, not as a precise bound.</p>"},{"location":"user-guide/error-estimation/#slider-error-estimation","title":"Slider Error Estimation","text":"<p><code>ChebyshevSlider</code> also supports <code>error_estimate()</code>. The slider error is the sum of the error estimates from each individual slide:</p> <pre><code>import math\nfrom pychebyshev import ChebyshevSlider\n\ndef f(x, _):\n    return math.sin(x[0]) + math.sin(x[1]) + math.sin(x[2])\n\nslider = ChebyshevSlider(\n    function=f,\n    num_dimensions=3,\n    domain=[[-1, 1], [-1, 1], [-1, 1]],\n    n_nodes=[11, 11, 11],\n    partition=[[0], [1], [2]],\n    pivot_point=[0.0, 0.0, 0.0],\n)\nslider.build()\nprint(f\"Slider error estimate: {slider.error_estimate():.2e}\")\n</code></pre> <p>Cross-group interaction error</p> <p>The slider error estimate captures per-slide interpolation error only -- the error from approximating each slide's low-dimensional function with Chebyshev polynomials. Error from the additive sliding decomposition itself (i.e., the cross-group coupling that the sliding formula ignores) is not included. For example, if \\(f(x_1, x_2) = x_1 \\cdot x_2\\) and the partition is <code>[[0], [1]]</code>, the sliding approximation is structurally unable to represent the product term, regardless of node count. The error estimate will report near-zero (each 1-D slide is well-resolved), but the true error can be large. For strongly coupled functions, always validate with test points.</p>"},{"location":"user-guide/error-estimation/#tensor-train-error-estimation","title":"Tensor Train Error Estimation","text":"<p><code>ChebyshevTT</code> also supports <code>error_estimate()</code>. The algorithm is analogous to the full-tensor case: for each core, convert to Chebyshev coefficients via DCT-II, take the maximum absolute value of the last coefficient slice (across all rank indices), and sum across dimensions.</p> <pre><code>from pychebyshev import ChebyshevTT\n\ntt = ChebyshevTT(my_func, 5, domain, [11]*5, max_rank=10)\ntt.build()\nprint(f\"TT error estimate: {tt.error_estimate():.2e}\")\n</code></pre> <p>Two sources of TT error</p> <p>The TT error estimate captures per-core coefficient truncation -- the error from using finitely many Chebyshev nodes within each core. It does not capture rank truncation error -- the error from representing the function with a low-rank TT decomposition. Think of it this way: even if every core perfectly resolves its 1-D slices (coefficient error \\(\\approx 0\\)), the TT may still be inaccurate because the rank is too low to capture all the coupling between dimensions.</p> <p>In practice, the rank truncation error dominates at low ranks (<code>max_rank</code> \\(\\leq 5\\)), while coefficient truncation dominates at high ranks with few nodes. The estimate is most reliable when <code>max_rank</code> is large enough that increasing it no longer improves accuracy.</p>"},{"location":"user-guide/error-estimation/#convergence-example","title":"Convergence Example","text":"<p>As the number of nodes increases, the error estimate should decrease -- rapidly for smooth functions. This example demonstrates spectral convergence for a 1-D function:</p> <pre><code>from pychebyshev import ChebyshevApproximation\nimport math\n\ndef f(x, _):\n    return math.sin(x[0])\n\nfor n in [5, 10, 15, 20, 25, 30]:\n    cheb = ChebyshevApproximation(f, 1, [[-1, 1]], [n])\n    cheb.build(verbose=False)\n    print(f\"n={n:2d}: error_estimate = {cheb.error_estimate():.2e}\")\n</code></pre> <p>For \\(\\sin(x)\\), which is entire (analytic everywhere in the complex plane), the coefficients decay exponentially, so you should see the estimate drop by several orders of magnitude as \\(n\\) grows.</p>"},{"location":"user-guide/error-estimation/#api-reference","title":"API Reference","text":"<p>For full method signatures and parameter details, see:</p> <ul> <li><code>ChebyshevApproximation.error_estimate()</code> -- error estimate for standard tensor interpolation.</li> <li><code>ChebyshevSlider.error_estimate()</code> -- error estimate for sliding approximation (sum of per-slide errors).</li> <li><code>ChebyshevTT.error_estimate()</code> -- error estimate for Tensor Train approximation (from coefficient cores).</li> </ul>"},{"location":"user-guide/extrude-slice/","title":"Extrusion &amp; Slicing","text":""},{"location":"user-guide/extrude-slice/#motivation-portfolio-combination","title":"Motivation -- Portfolio Combination","text":"<p>In practice, trades depend on different subsets of risk factors.  Trade A might depend on (spot, rate) while Trade B depends on (spot, vol).  The v0.7.0 algebra operators require operands on the same grid, so these two proxies cannot be added directly.</p> <p>Extrusion solves this by adding new dimensions where the function is constant.  After extruding both trades to a common 3D grid (spot, rate, vol), they can be combined with the standard <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> operators:</p> <pre><code>portfolio = trade_a_3d + trade_b_3d\n</code></pre> <p>Slicing is the inverse: it fixes a dimension at a specific value, reducing dimensionality via barycentric interpolation.  Together, extrusion and slicing form the bridge between Chebyshev proxies on heterogeneous risk-factor sets.</p> <p>When to use extrude/slice</p> <p>Use extrusion when you need to combine Chebyshev interpolants that live on different sets of dimensions.  Use slicing to project a high-dimensional interpolant onto a lower-dimensional subspace (e.g., fixing a parameter at its current market value).</p>"},{"location":"user-guide/extrude-slice/#mathematical-basis","title":"Mathematical Basis","text":""},{"location":"user-guide/extrude-slice/#partition-of-unity","title":"Partition of Unity","text":"<p>The barycentric basis functions satisfy a fundamental identity:</p> \\[ \\sum_{j=0}^{n} \\ell_j(x) = 1 \\] <p>for all \\(x\\) in the domain.  This is because any polynomial interpolation scheme reproduces constant functions exactly -- the constant \\(1\\) is interpolated by \\(\\sum_j 1 \\cdot \\ell_j(x) = 1\\).</p> <p>Reference</p> <p>Berrut &amp; Trefethen (2004), \"Barycentric Lagrange Interpolation\", SIAM Review 46(3):501--517, Section 2.</p>"},{"location":"user-guide/extrude-slice/#extrusion-proof","title":"Extrusion Proof","text":"<p>Given a \\(d\\)-dimensional CT with values \\(v_{i_1,\\ldots,i_d}\\), the extruded \\((d+1)\\)-dimensional CT inserts a new axis at position \\(k\\) with \\(M\\) Chebyshev nodes, replicating values:</p> \\[ \\hat{v}_{i_1,\\ldots,i_{k-1},\\,j,\\,i_k,\\ldots,i_d} = v_{i_1,\\ldots,i_d} \\quad \\forall\\; j = 0,\\ldots,M-1 \\] <p>Evaluating at any point \\((x_1,\\ldots,x_{k-1},x^*,x_k,\\ldots,x_d)\\):</p> \\[ p(\\mathbf{x}) = \\sum_{\\text{all indices}} v_{i_1,\\ldots,i_d} \\cdot \\ell_j^{(k)}(x^*) \\cdot \\prod_{m \\neq k} \\ell_{i_m}^{(m)}(x_m) \\] <p>Since the values don't depend on \\(j\\), the \\(j\\)-sum factors out:</p> \\[ = \\underbrace{\\left(\\sum_{j=0}^{M-1} \\ell_j^{(k)}(x^*)\\right)}_{= 1 \\;\\text{(partition of unity)}} \\cdot \\sum_{i_1,\\ldots,i_d} v_{i_1,\\ldots,i_d} \\prod_{m \\neq k} \\ell_{i_m}^{(m)}(x_m) = p_{\\text{orig}}(\\mathbf{x}_{\\text{orig}}) \\] <p>Result: The extruded CT evaluates to the same value as the original, regardless of the new coordinate.  Extrusion is exact.</p>"},{"location":"user-guide/extrude-slice/#slicing-proof","title":"Slicing Proof","text":"<p>Given a \\(d\\)-dimensional CT, fixing dimension \\(k\\) at value \\(x^*\\):</p> \\[ p(x_1,\\ldots,x_{k-1},x^*,x_{k+1},\\ldots,x_d) = \\sum_{i_1,\\ldots,i_d} v_{i_1,\\ldots,i_d} \\prod_{m=1}^{d} \\ell_{i_m}^{(m)}(x_m) \\bigg|_{x_k = x^*} \\] <p>Factoring out the \\(k\\)-th dimension:</p> \\[ = \\sum_{i_1,\\ldots,i_{k-1},i_{k+1},\\ldots,i_d} \\underbrace{\\left(\\sum_{i_k} v_{i_1,\\ldots,i_d} \\cdot \\ell_{i_k}^{(k)}(x^*)\\right)}_{\\hat{v}_{i_1,\\ldots,i_{k-1},i_{k+1},\\ldots,i_d}} \\prod_{m \\neq k} \\ell_{i_m}^{(m)}(x_m) \\] <p>The contracted values \\(\\hat{v}\\) define a valid \\((d-1)\\)-dimensional CT.</p> <p>Fast path: When \\(x^*\\) coincides with a Chebyshev node \\(x_m^{(k)}\\) (within tolerance \\(10^{-14}\\)), the basis function simplifies to \\(\\ell_{i_k}^{(k)}(x_m) = \\delta_{i_k,m}\\), so \\(\\hat{v} = v_{\\ldots,m,\\ldots}\\) -- a simple <code>np.take</code> (no arithmetic needed).</p>"},{"location":"user-guide/extrude-slice/#extrude-then-slice-identity","title":"Extrude-then-Slice = Identity","text":"<p>If we extrude along dimension \\(k\\) and then slice at any value \\(x^*\\) along \\(k\\):</p> \\[ \\text{slice}(\\text{extrude}(T, k), k, x^*) = T \\] <p>Proof.  Extrusion replicates values along \\(k\\), then slicing contracts via \\(\\sum_j v \\cdot \\ell_j(x^*) = v \\cdot 1 = v\\).</p>"},{"location":"user-guide/extrude-slice/#error-bounds","title":"Error Bounds","text":"<ul> <li>Extrusion: No approximation error introduced (exact operation).</li> <li>Slicing: The sliced CT evaluates the polynomial interpolant at \\(x_k = x^*\\).   No additional error beyond the original approximation error:   if \\(\\|f - p\\|_\\infty \\leq \\epsilon\\), then   \\(\\|f(\\cdot, x^*) - p(\\cdot, x^*)\\|_\\infty \\leq \\epsilon\\).</li> </ul> <p>Book reference</p> <p>Extrusion and slicing of Chebyshev Tensors is described in Section 24.2.1, Listing 24.15 (slice) and Listing 24.16 (extrude) of Ruiz &amp; Zeron (2021), Machine Learning for Risk Calculations, Wiley Finance.</p>"},{"location":"user-guide/extrude-slice/#quick-start","title":"Quick Start","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\ndef f(x, _): return math.sin(x[0]) + x[1]\ndef g(x, _): return math.cos(x[0]) * x[1]\n\n# Trade A depends on (spot, rate)\ntrade_a = ChebyshevApproximation(f, 2, [[80, 120], [0.01, 0.08]], [11, 11])\ntrade_a.build()\n\n# Trade B depends on (spot, vol)\ntrade_b = ChebyshevApproximation(g, 2, [[80, 120], [0.15, 0.35]], [11, 11])\ntrade_b.build()\n\n# Extrude both to 3D: (spot, rate, vol)\ntrade_a_3d = trade_a.extrude((2, (0.15, 0.35), 11))  # add vol dim\ntrade_b_3d = trade_b.extrude((1, (0.01, 0.08), 11))  # add rate dim\n\n# Combine into portfolio\nportfolio = trade_a_3d + trade_b_3d\nprice = portfolio.vectorized_eval([100.0, 0.05, 0.25], [0, 0, 0])\n</code></pre>"},{"location":"user-guide/extrude-slice/#supported-operations","title":"Supported Operations","text":"Class <code>extrude()</code> <code>slice()</code> <code>ChebyshevApproximation</code> Yes Yes <code>ChebyshevSpline</code> Yes Yes <code>ChebyshevSlider</code> Yes Yes <code>ChebyshevTT</code> No No"},{"location":"user-guide/extrude-slice/#extrude-api","title":"Extrude API","text":"<pre><code>result = cheb.extrude(params)\n</code></pre> <p>Parameters</p> Parameter Type Description <code>params</code> tuple or list of tuples <code>(dim_index, (lo, hi), n_nodes)</code> <ul> <li><code>dim_index</code> -- position in the output space (0 = prepend, <code>d</code> = append)</li> <li><code>(lo, hi)</code> -- domain bounds for the new dimension</li> <li><code>n_nodes</code> -- number of Chebyshev nodes (must match other CTs for later algebra)</li> </ul> <p>Returns: A new interpolant of the same type, already built, with <code>function=None</code>.</p> <p>Errors:</p> <ul> <li><code>RuntimeError</code> if the interpolant has not been built</li> <li><code>ValueError</code> if <code>dim_index</code> is out of range, duplicated, <code>lo &gt;= hi</code>, or <code>n_nodes &lt; 2</code></li> </ul> <p>Multi-extrude: 1D to 3D</p> <pre><code>cheb_1d = ChebyshevApproximation(f, 1, [[-1, 1]], [15])\ncheb_1d.build()\n\n# Add two dimensions at once\ncheb_3d = cheb_1d.extrude([\n    (1, (0.0, 5.0), 11),\n    (2, (-2.0, 2.0), 9),\n])\n</code></pre>"},{"location":"user-guide/extrude-slice/#slice-api","title":"Slice API","text":"<pre><code>result = cheb.slice(params)\n</code></pre> <p>Parameters</p> Parameter Type Description <code>params</code> tuple or list of tuples <code>(dim_index, value)</code> <ul> <li><code>dim_index</code> -- dimension to fix (0-indexed in the current object)</li> <li><code>value</code> -- point at which to fix (must be within the domain)</li> </ul> <p>Returns: A new interpolant of the same type, already built, with <code>function=None</code>.</p> <p>Errors:</p> <ul> <li><code>RuntimeError</code> if the interpolant has not been built</li> <li><code>ValueError</code> if <code>value</code> is outside the domain, <code>dim_index</code> is out of range,   duplicated, or if slicing all dimensions</li> </ul> <p>Slice 3D to 1D</p> <pre><code>cheb_3d = ChebyshevApproximation(f, 3, [[-1, 1]] * 3, [11, 11, 11])\ncheb_3d.build()\n\n# Fix dim 1 and dim 2\ncheb_1d = cheb_3d.slice([(1, 0.5), (2, -0.3)])\n</code></pre> <p>Fast path at exact nodes</p> <p>When the slice value coincides with a Chebyshev node (within \\(10^{-14}\\)), the contraction reduces to <code>np.take</code> -- a simple array index with no floating-point arithmetic.</p>"},{"location":"user-guide/extrude-slice/#compatibility-with-algebra","title":"Compatibility with Algebra","text":"<p>Extrusion is the key enabler for the v0.7.0 algebra operators.  After extruding two CTs to a common grid, all standard operators work:</p> <pre><code># Different risk factors\nct_a = ChebyshevApproximation(f, 2, [[80, 120], [0.01, 0.08]], [11, 11])\nct_b = ChebyshevApproximation(g, 2, [[80, 120], [0.15, 0.35]], [11, 11])\nct_a.build(); ct_b.build()\n\n# Extrude to common 3D: (spot, rate, vol)\nct_a_3d = ct_a.extrude((2, (0.15, 0.35), 11))\nct_b_3d = ct_b.extrude((1, (0.01, 0.08), 11))\n\n# Now all algebra operators work\nportfolio = 0.6 * ct_a_3d + 0.4 * ct_b_3d\nhedged    = ct_a_3d - ct_b_3d\nscaled    = 2.0 * ct_a_3d\n</code></pre> <p>The compatibility requirements from Chebyshev Algebra apply to the extruded results: same domain, node counts, derivative order, and number of dimensions.</p>"},{"location":"user-guide/extrude-slice/#derivatives","title":"Derivatives","text":"<p>Extrusion: Derivatives in the original dimensions are preserved. Derivatives with respect to the new dimension are zero (the function is constant along the new axis).  This follows from \\(\\mathcal{D}_k \\cdot [c, c, \\ldots, c]^T = \\mathbf{0}\\).</p> <p>Slicing: Derivatives in the remaining dimensions are preserved.  The sliced CT has valid spectral differentiation matrices for all surviving dimensions.</p> <pre><code># Extrude: derivative w.r.t. new dim is zero\nct_3d = ct_2d.extrude((2, (0.0, 1.0), 11))\nassert abs(ct_3d.vectorized_eval([0.5, 0.3, 0.7], [0, 0, 1])) &lt; 1e-12\n\n# Slice: derivative in remaining dim preserved\nct_1d = ct_2d.slice((1, 0.5))\nd_dx = ct_1d.vectorized_eval([0.3], [1])  # first derivative w.r.t. dim 0\n</code></pre>"},{"location":"user-guide/extrude-slice/#serialization","title":"Serialization","text":"<p>Extruded and sliced interpolants support <code>save()</code> and <code>load()</code> just like any other built interpolant:</p> <pre><code>ct_3d = ct_2d.extrude((2, (0.0, 1.0), 11))\nct_3d.save(\"extruded.pkl\")\n\nloaded = ChebyshevApproximation.load(\"extruded.pkl\")\nloaded.vectorized_eval([0.5, 0.3, 0.7], [0, 0, 0])  # works identically\n</code></pre>"},{"location":"user-guide/extrude-slice/#class-specific-notes","title":"Class-Specific Notes","text":""},{"location":"user-guide/extrude-slice/#chebyshevspline","title":"ChebyshevSpline","text":"<p>When extruding a spline, each piece is extruded independently.  The new dimension gets <code>knots=[]</code> (no interior knots) and a single interval.</p> <p>When slicing a spline, only the pieces whose interval along the sliced dimension contains the slice value survive.  Each surviving piece is then sliced via its underlying <code>ChebyshevApproximation.slice()</code>.</p>"},{"location":"user-guide/extrude-slice/#chebyshevslider","title":"ChebyshevSlider","text":"<p>When extruding a slider, the new dimension becomes its own single-dim slide group with <code>tensor_values = np.full(n, pivot_value)</code>, so the slide contributes zero: \\(s_{\\text{new}}(x) - pv = 0\\) for all \\(x\\).  The partition indices for existing dimensions are remapped accordingly.</p> <p>When slicing a slider, two cases arise:</p> <ul> <li>Multi-dim group: The slide's <code>ChebyshevApproximation</code> is sliced at   the local dimension index within the group.</li> <li>Single-dim group: The slide is evaluated at the slice value, giving   a constant \\(s_{g^*}(v)\\).  The shift \\(\\delta = s_{g^*}(v) - pv\\) is   absorbed into <code>pivot_value</code> and each remaining slide's tensor values.</li> </ul>"},{"location":"user-guide/extrude-slice/#limitations","title":"Limitations","text":"<ul> <li>No <code>ChebyshevTT</code> support -- extrusion and slicing for Tensor Train   interpolants are not currently implemented.</li> <li>Operand must be built -- <code>build()</code> must have been called before   calling <code>extrude()</code> or <code>slice()</code>.</li> <li>No cross-type operations -- you cannot extrude a <code>ChebyshevSpline</code>   and then add it to a <code>ChebyshevApproximation</code>.</li> <li>Result has <code>function=None</code> -- the extruded/sliced interpolant cannot   call <code>build()</code> again, since it has no underlying function reference.</li> </ul>"},{"location":"user-guide/greeks/","title":"Computing Greeks","text":"<p>PyChebyshev computes option Greeks (and any partial derivatives) analytically using spectral differentiation matrices \u2014 no finite differences needed.</p>"},{"location":"user-guide/greeks/#derivative-specification","title":"Derivative Specification","text":"<p>Derivatives are specified as a list of integers, one per dimension. Each integer is the derivative order with respect to that dimension.</p> <p>For a 5D function \\(V(S, K, T, \\sigma, r)\\):</p> Greek <code>derivative_order</code> Mathematical Price <code>[0, 0, 0, 0, 0]</code> \\(V\\) Delta <code>[1, 0, 0, 0, 0]</code> \\(\\partial V / \\partial S\\) Gamma <code>[2, 0, 0, 0, 0]</code> \\(\\partial^2 V / \\partial S^2\\) Vega <code>[0, 0, 0, 1, 0]</code> \\(\\partial V / \\partial \\sigma\\) Rho <code>[0, 0, 0, 0, 1]</code> \\(\\partial V / \\partial r\\)"},{"location":"user-guide/greeks/#example-black-scholes-greeks","title":"Example: Black-Scholes Greeks","text":"<pre><code>from pychebyshev import ChebyshevApproximation\n\ndef black_scholes_call(x, _):\n    S, K, T, sigma, r = x\n    # ... your pricing function here\n    return price\n\ncheb = ChebyshevApproximation(\n    black_scholes_call, 5,\n    domain=[[80, 120], [90, 110], [0.25, 1.0], [0.15, 0.35], [0.01, 0.08]],\n    n_nodes=[11, 11, 11, 11, 11],\n)\ncheb.build()\n\npoint = [100, 100, 1.0, 0.25, 0.05]\n\n# All Greeks at once (most efficient)\nprice, delta, gamma, vega, rho = cheb.vectorized_eval_multi(point, [\n    [0, 0, 0, 0, 0],\n    [1, 0, 0, 0, 0],\n    [2, 0, 0, 0, 0],\n    [0, 0, 0, 1, 0],\n    [0, 0, 0, 0, 1],\n])\n</code></pre>"},{"location":"user-guide/greeks/#how-it-works","title":"How It Works","text":"<ol> <li>At build time: Pre-compute differentiation matrix \\(D\\) from node positions</li> <li>At query time: Apply \\(D\\) to the function value tensor before barycentric interpolation</li> <li>For second derivatives: apply \\(D\\) twice (\\(D^2 \\mathbf{f}\\))</li> <li>Interpolate the resulting derivative values to the query point</li> </ol> <p>This provides exact derivatives of the interpolating polynomial. Because the differentiation matrix computes derivatives of the degree-\\(n\\) polynomial \\(p(x)\\) exactly (within machine precision), and \\(p(x)\\) converges spectrally to \\(f(x)\\), the derivative \\(p'(x)\\) also converges spectrally to \\(f'(x)\\).</p> <p>See Berrut &amp; Trefethen (2004) for the derivation of the differentiation matrix formulas. For the full theory of spectral differentiation, see Trefethen, Approximation Theory and Approximation Practice, SIAM 2019, Chapter 11.</p> <p>Tensor Train derivatives</p> <p><code>ChebyshevTT</code> uses finite differences instead of analytical derivatives, because the spectral differentiation matrix requires the full tensor (which TT avoids storing). FD derivatives are still accurate to within a few hundredths of a percent for first derivatives. See Tensor Train: Derivatives.</p>"},{"location":"user-guide/greeks/#accuracy","title":"Accuracy","text":"<p>With 11 nodes per dimension on a 5D Black-Scholes test:</p> Greek Max Error Delta &lt; 0.01% Gamma &lt; 0.01% Vega ~1.98% Rho &lt; 0.01% <p>Vega has slightly higher error because volatility sensitivity involves a product of multiple terms, but remains well within practical tolerance.</p>"},{"location":"user-guide/serialization/","title":"Saving &amp; Loading Interpolants","text":""},{"location":"user-guide/serialization/#why-save","title":"Why Save?","text":"<p>Building a Chebyshev interpolant is the expensive step \u2014 it evaluates your function at every node in the tensor grid (e.g. \\(11^5 = 161{,}051\\) evaluations for a 5-D problem). Once built, evaluation takes microseconds.</p> <p>Saving a built interpolant lets you:</p> <ul> <li>Build once, evaluate forever \u2014 skip the build step in production</li> <li>Share models \u2014 distribute pre-built interpolants to team members or across machines</li> <li>Persist across sessions \u2014 save your work and reload it later</li> </ul>"},{"location":"user-guide/serialization/#saving-a-built-interpolant","title":"Saving a Built Interpolant","text":"<p>All three public classes -- <code>ChebyshevApproximation</code>, <code>ChebyshevSlider</code>, and <code>ChebyshevTT</code> -- provide <code>save()</code> and <code>load()</code> methods:</p> <pre><code>import math\nfrom pychebyshev import ChebyshevApproximation\n\ndef my_func(x, _):\n    return math.sin(x[0]) * math.exp(-x[1])\n\ncheb = ChebyshevApproximation(\n    my_func, 2, [[-1, 1], [0, 2]], [15, 15]\n)\ncheb.build()\n\n# Save to disk\ncheb.save(\"interpolant.pkl\")\n</code></pre> <p>For a <code>ChebyshevSlider</code>:</p> <pre><code>from pychebyshev import ChebyshevSlider\n\nslider = ChebyshevSlider(\n    my_func, 2, [[-1, 1], [0, 2]], [15, 15],\n    partition=[[0], [1]],\n    pivot_point=[0.0, 1.0],\n)\nslider.build()\n\nslider.save(\"slider.pkl\")\n</code></pre> <p>For a <code>ChebyshevTT</code>:</p> <pre><code>from pychebyshev import ChebyshevTT\n\ntt = ChebyshevTT(my_func, 5, domain, [11]*5, max_rank=10)\ntt.build()\ntt.save(\"tt_model.pkl\")\n</code></pre>"},{"location":"user-guide/serialization/#loading-an-interpolant","title":"Loading an Interpolant","text":"<p>Use the <code>load()</code> class method \u2014 no rebuild needed:</p> <pre><code>from pychebyshev import ChebyshevApproximation, ChebyshevSlider, ChebyshevTT\n\n# Load and evaluate immediately\ncheb = ChebyshevApproximation.load(\"interpolant.pkl\")\nvalue = cheb.vectorized_eval([0.5, 1.0], [0, 0])\n\n# Works the same for sliders\nslider = ChebyshevSlider.load(\"slider.pkl\")\nvalue = slider.eval([0.5, 1.0], [0, 0])\n\n# And for Tensor Train\ntt = ChebyshevTT.load(\"tt_model.pkl\")\nvalue = tt.eval([0.5, 1.0, 0.3, 0.2, 0.05])\n</code></pre> <p>The loaded <code>ChebyshevApproximation</code> supports all evaluation methods (<code>vectorized_eval</code>, <code>vectorized_eval_multi</code>, <code>vectorized_eval_batch</code>). The loaded <code>ChebyshevSlider</code> supports <code>eval</code> and <code>eval_multi</code>. The loaded <code>ChebyshevTT</code> supports <code>eval</code>, <code>eval_batch</code>, and <code>eval_multi</code>.</p>"},{"location":"user-guide/serialization/#inspecting-objects","title":"Inspecting Objects","text":"<p>Use <code>repr()</code> for a compact summary and <code>print()</code> for a detailed view:</p> <pre><code>cheb = ChebyshevApproximation.load(\"interpolant.pkl\")\n\nrepr(cheb)\n# ChebyshevApproximation(dims=2, nodes=[15, 15], built=True)\n\nprint(cheb)\n# ChebyshevApproximation (2D, built)\n#   Nodes:       [15, 15] (225 total)\n#   Domain:      [-1, 1] x [0, 2]\n#   Build:       0.002s, 225 evaluations\n#   Derivatives: up to order 2\n</code></pre> <p>For a slider:</p> <pre><code>print(slider)\n# ChebyshevSlider (5D, 2 slides, built)\n#   Partition: [[0, 1, 2], [3, 4]]\n#   Pivot:     [100.0, 1.0, 0.25, 0.05, 0.2]\n#   Nodes:     [11, 11, 11, 11, 11] (1,452 vs 161,051 full tensor)\n#   Domain:    [80.0, 120.0] x [0.5, 2.0] x [0.01, 0.5] x [0.01, 0.1] x [0.05, 0.5]\n#   Slides:\n#     [0] dims [0, 1, 2]: 1,331 evals, built in 0.189s\n#     [1] dims [3, 4]:     121 evals, built in 0.021s\n</code></pre> <p>This is useful for verifying that a loaded interpolant matches your expectations before using it.</p>"},{"location":"user-guide/serialization/#limitations","title":"Limitations","text":"<ul> <li> <p>The original function is not saved. Only the numerical data needed for   evaluation (nodes, weights, tensor values, differentiation matrices) is persisted.   After loading, <code>obj.function</code> is <code>None</code>.</p> </li> <li> <p>Calling <code>build()</code> on a loaded object requires reassigning a function first:</p> <pre><code>cheb = ChebyshevApproximation.load(\"interpolant.pkl\")\ncheb.function = my_func  # reassign before rebuilding\ncheb.build()\n</code></pre> </li> <li> <p>Version compatibility. If you load a file saved with a different version of   PyChebyshev, a warning is emitted. Evaluation results should be identical unless   internal data layout changed between versions.</p> </li> </ul> <p>Security</p> <p><code>load()</code> uses Python's <code>pickle</code> module internally. Pickle can execute arbitrary code during deserialization. Only load files you trust. Do not load interpolants from untrusted or unverified sources.</p>"},{"location":"user-guide/sliding/","title":"Sliding Technique","text":"<p>The Sliding Technique enables Chebyshev approximation of high-dimensional functions by decomposing them into a sum of low-dimensional interpolants. This sidesteps the curse of dimensionality at the cost of losing cross-group interactions.</p>"},{"location":"user-guide/sliding/#motivation","title":"Motivation","text":"<p>A full tensor Chebyshev interpolant on \\(n\\) dimensions with \\(m\\) nodes per dimension requires \\(m^n\\) function evaluations. For \\(n = 10\\) and \\(m = 11\\), that is over 25 billion evaluations \u2014 clearly infeasible.</p> <p>The sliding technique partitions the dimensions into small groups and builds a separate Chebyshev interpolant (a slide) for each group, with all other dimensions fixed at a pivot point. The total cost becomes the sum of the group grid sizes rather than their product.</p>"},{"location":"user-guide/sliding/#algorithm","title":"Algorithm","text":"<p>Given \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\), a pivot point \\(\\mathbf{z} = (z_1, \\ldots, z_n)\\), and a partition of dimensions into \\(k\\) groups:</p> <ol> <li>Evaluate the pivot value \\(v = f(\\mathbf{z})\\).</li> <li>For each group \\(i\\), build a slide \\(s_i\\) \u2014 a Chebyshev interpolant on the group's dimensions, with all other dimensions fixed at their pivot values.</li> <li>Evaluate using the additive formula:</li> </ol> \\[ f(\\mathbf{x}) \\approx v + \\sum_{i=1}^{k} \\bigl[ s_i(\\mathbf{x}_{G_i}) - v \\bigr] \\] <p>where \\(\\mathbf{x}_{G_i}\\) denotes the components of \\(\\mathbf{x}\\) belonging to group \\(i\\).</p>"},{"location":"user-guide/sliding/#when-to-use-sliding","title":"When to Use Sliding","text":"<p>Sliding works well when:</p> <ul> <li>The function is additively separable or nearly so (e.g., \\(\\sin(x_1) + \\sin(x_2) + \\sin(x_3)\\)).</li> <li>Cross-group interactions are weak relative to within-group effects.</li> <li>The number of dimensions is too large for full tensor interpolation (say, \\(n &gt; 6\\)).</li> </ul> <p>Sliding does not work well when:</p> <ul> <li>Variables in different groups are strongly coupled (e.g., Black-Scholes where \\(S\\), \\(T\\), and \\(\\sigma\\) interact multiplicatively).</li> <li>High accuracy is required far from the pivot point.</li> </ul> <p>Alternative: Tensor Train</p> <p>For general (non-separable) high-dimensional functions, consider <code>ChebyshevTT</code> instead. TT-Cross captures cross-variable coupling that the sliding decomposition misses, at the cost of using finite differences for derivatives instead of analytical spectral differentiation.</p> <p>Choosing the partition</p> <p>Group variables that have strong non-linear interactions together. For example, if \\(f = x_1^3 x_2^2 + x_3\\), group \\((x_1, x_2)\\) in one slide and \\(x_3\\) in another.</p>"},{"location":"user-guide/sliding/#usage","title":"Usage","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevSlider\n\n# Additively separable function\ndef f(x, _):\n    return math.sin(x[0]) + math.sin(x[1]) + math.sin(x[2])\n\nslider = ChebyshevSlider(\n    function=f,\n    num_dimensions=3,\n    domain=[[-1, 1], [-1, 1], [-1, 1]],\n    n_nodes=[11, 11, 11],\n    partition=[[0], [1], [2]],       # each dim is its own slide\n    pivot_point=[0.0, 0.0, 0.0],\n)\nslider.build()\n\n# Evaluate function value\nval = slider.eval([0.5, 0.3, -0.2], [0, 0, 0])\n\n# Evaluate derivative w.r.t. x0\ndfdx0 = slider.eval([0.5, 0.3, -0.2], [1, 0, 0])\n</code></pre>"},{"location":"user-guide/sliding/#multi-dimensional-slides","title":"Multi-dimensional slides","text":"<p>For functions with within-group coupling, use larger groups:</p> <pre><code>def g(x, _):\n    return x[0]**3 * x[1]**2 + math.sin(x[2]) + math.sin(x[3])\n\nslider = ChebyshevSlider(\n    function=g,\n    num_dimensions=4,\n    domain=[[-2, 2], [-2, 2], [-1, 1], [-1, 1]],\n    n_nodes=[12, 12, 8, 8],\n    partition=[[0, 1], [2], [3]],    # 2D + 1D + 1D\n    pivot_point=[0.0, 0.0, 0.0, 0.0],\n)\nslider.build()\n</code></pre>"},{"location":"user-guide/sliding/#build-cost-comparison","title":"Build cost comparison","text":"<pre><code># Full tensor: 12 * 12 * 8 * 8 = 9,216 evaluations\n# Sliding:     12*12 + 8 + 8   = 160 evaluations  (57x fewer)\nprint(f\"Slider build evaluations: {slider.total_build_evals}\")\n</code></pre>"},{"location":"user-guide/sliding/#derivatives","title":"Derivatives","text":"<p>The slider supports analytical derivatives through its slides. Only the slide containing the differentiated dimension contributes:</p> \\[ \\frac{\\partial}{\\partial x_j} f(\\mathbf{x}) \\approx \\frac{\\partial}{\\partial x_j} s_i(\\mathbf{x}_{G_i}) \\] <p>where \\(j \\in G_i\\). The pivot value \\(v\\) is constant and drops out.</p> <pre><code># Multiple derivatives at once\nresults = slider.eval_multi(\n    [0.5, 0.3, -0.2],\n    [\n        [0, 0, 0],  # function value\n        [1, 0, 0],  # d/dx0\n        [0, 1, 0],  # d/dx1\n        [0, 0, 1],  # d/dx2\n    ],\n)\n</code></pre>"},{"location":"user-guide/sliding/#limitations","title":"Limitations","text":""},{"location":"user-guide/sliding/#cross-group-derivatives-are-zero","title":"Cross-group derivatives are zero","text":"<p>Because slides are independent functions of disjoint variable groups, mixed partial derivatives across groups are exactly zero. For example, with partition <code>[[0, 1], [2]]</code>:</p> <ul> <li>\\(\\frac{\\partial^2 f}{\\partial x_0 \\partial x_1}\\) \u2014 computed within the <code>[0, 1]</code> slide (correct)</li> <li>\\(\\frac{\\partial^2 f}{\\partial x_0 \\partial x_2}\\) \u2014 returns 0 (x\u2080 and x\u2082 are in different slides)</li> </ul> <p>This is mathematically correct for the sliding approximation, but may differ from the true function's cross-derivatives. If cross-group sensitivities matter, group those variables together or use full tensor interpolation.</p>"},{"location":"user-guide/sliding/#accuracy-degrades-far-from-pivot","title":"Accuracy degrades far from pivot","text":"<p>The sliding approximation is most accurate near the pivot point. As the evaluation point moves away from the pivot in multiple dimensions simultaneously, cross-coupling errors accumulate. For strongly coupled functions like Black-Scholes, this can produce 20-50% errors at domain boundaries.</p>"},{"location":"user-guide/sliding/#api-reference","title":"API Reference","text":"<p>Chebyshev Sliding approximation for high-dimensional functions.</p> <p>Decomposes f(x_1, ..., x_n) into a sum of low-dimensional Chebyshev interpolants (slides) around a pivot point z:</p> <pre><code>f(x) \u2248 f(z) + \u03a3_i [s_i(x_group_i) - f(z)]\n</code></pre> <p>where each slide s_i is a ChebyshevApproximation built on a subset of dimensions with the remaining dimensions fixed at z.</p> <p>This trades accuracy for dramatically reduced build cost: instead of evaluating f at n_1 \u00d7 n_2 \u00d7 ... \u00d7 n_d grid points (exponential), the slider evaluates at n_1 \u00d7 n_2 + n_3 \u00d7 n_4 + ... (sum of products within each group).</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate. Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Total number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [lo, hi] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension.</p> required <code>partition</code> <code>list of list of int</code> <p>Grouping of dimension indices into slides. Each dimension must appear in exactly one group. E.g. <code>[[0,1,2], [3,4]]</code> creates a 3D slide for dims 0,1,2 and a 2D slide for dims 3,4.</p> required <code>pivot_point</code> <code>list of float</code> <p>Reference point z around which slides are built.</p> required <code>max_derivative_order</code> <code>int</code> <p>Maximum derivative order to pre-compute (default 2).</p> <code>2</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return math.sin(x[0]) + math.sin(x[1]) + math.sin(x[2])\n&gt;&gt;&gt; slider = ChebyshevSlider(\n...     f, 3, [[-1,1], [-1,1], [-1,1]], [11,11,11],\n...     partition=[[0], [1], [2]],\n...     pivot_point=[0.0, 0.0, 0.0],\n... )\n&gt;&gt;&gt; slider.build(verbose=False)\n&gt;&gt;&gt; round(slider.eval([0.5, 0.3, 0.1], [0,0,0]), 4)\n0.8764\n</code></pre>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.total_build_evals","title":"<code>total_build_evals</code>  <code>property</code>","text":"<p>Total number of function evaluations used during build.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.build","title":"<code>build(verbose=True)</code>","text":"<p>Build all slides by evaluating the function at slide-specific grids.</p> <p>For each slide, dimensions outside the slide group are fixed at their pivot values.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress. Default is True.</p> <code>True</code>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.eval","title":"<code>eval(point, derivative_order)</code>","text":"<p>Evaluate the slider approximation at a point.</p> <p>Uses Equation 7.5 from Ruiz &amp; Zeron (2021):     f(x) \u2248 f(z) + \u03a3_i [s_i(x_i) - f(z)]</p> <p>For derivatives, only the slide containing that dimension contributes.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full n-dimensional space.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order for each dimension (0 = function value).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Approximated function value or derivative.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.eval_multi","title":"<code>eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate slider at multiple derivative orders for the same point.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full n-dimensional space.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>Results for each derivative order.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate the sliding approximation error.</p> <p>Returns the sum of per-slide Chebyshev error estimates. Each slide's error is estimated independently using the Chebyshev coefficient method from Ruiz &amp; Zeron (2021), Section 3.4.</p> <p>Note: This captures per-slide interpolation error only. Cross-group interaction error (inherent to the sliding decomposition) is not included.</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated interpolation error (per-slide sum).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state from a pickled dict.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.save","title":"<code>save(path)</code>","text":"<p>Save the built slider to a file.</p> <p>The original function is not saved \u2014 only the numerical data needed for evaluation. The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the slider has not been built yet.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved slider from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>. Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevSlider</code> <p>The restored slider.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally. Pickle can execute arbitrary code during deserialization. Only load files you trust.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.extrude","title":"<code>extrude(params)</code>","text":"<p>Add new dimensions where the function is constant.</p> <p>Each new dimension becomes its own single-dim slide group with <code>tensor_values = np.full(n, pivot_value)</code>, so that <code>s_new(x) - pivot_value = 0</code> for all x (no contribution to the sliding sum).  This is the partition-of-unity property: the barycentric weights sum to 1, so a constant tensor produces the same value for any coordinate.</p> <p>Existing slide groups have their dimension indices remapped to account for the inserted dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, (lo, hi), n_nodes)</code> or a list of such tuples.  <code>dim_index</code> is the position in the output space (0-indexed).  <code>n_nodes</code> must be &gt;= 2 and <code>lo &lt; hi</code>.</p> required <p>Returns:</p> Type Description <code>ChebyshevSlider</code> <p>A new, higher-dimensional slider (already built). The result has <code>function=None</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the slider has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If <code>dim_index</code> is out of range, duplicated, <code>lo &gt;= hi</code>, or <code>n_nodes &lt; 2</code>.</p>"},{"location":"user-guide/sliding/#pychebyshev.slider.ChebyshevSlider.slice","title":"<code>slice(params)</code>","text":"<p>Fix one or more dimensions at given values, reducing dimensionality.</p> <p>Two cases per sliced dimension:</p> <ul> <li>Multi-dim group: The slide's <code>ChebyshevApproximation</code> is   sliced at the local dimension index via barycentric contraction.   When the slice value coincides with a Chebyshev node (within   1e-14), the contraction reduces to an exact <code>np.take</code>   (fast path).  The dimension is removed from the group.</li> <li>Single-dim group: The slide is evaluated at the value,   giving a constant <code>s_val</code>.  The shift   <code>delta = s_val - pivot_value</code> is absorbed into   <code>pivot_value</code> and each remaining slide's   <code>tensor_values</code>, and the group is removed entirely.</li> </ul> <p>Remaining dimension indices in all groups are remapped downward to stay contiguous.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, value)</code> or a list of such tuples. <code>value</code> must lie within the domain for that dimension.</p> required <p>Returns:</p> Type Description <code>ChebyshevSlider</code> <p>A new, lower-dimensional slider (already built). The result has <code>function=None</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the slider has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If a slice value is outside the domain, if slicing all dimensions, or if <code>dim_index</code> is out of range or duplicated.</p>"},{"location":"user-guide/spline/","title":"Chebyshev Splines","text":""},{"location":"user-guide/spline/#the-gibbs-phenomenon","title":"The Gibbs Phenomenon","text":"<p>Chebyshev interpolation converges exponentially for smooth (analytic) functions -- this is the spectral advantage that makes the method so powerful.  But when the target function has a discontinuity or a kink, this advantage disappears.</p> <p>Jump discontinuities.  For a function \\(f\\) with a jump discontinuity at \\(c \\in (a, b)\\), the Chebyshev interpolant converges only as \\(O(1/n)\\) pointwise away from \\(c\\).  Near \\(c\\), oscillations persist regardless of how many nodes you add -- this is the classical Gibbs phenomenon.</p> <p>Kinks.  For a function that is continuous but whose derivative is discontinuous at \\(c\\) -- for example \\(|x|\\) at \\(x = 0\\) or a call payoff \\(\\max(S - K, 0)\\) at \\(S = K\\) -- the situation is better but still algebraic: convergence is \\(O(1/n^2)\\) instead of exponential.  This means that increasing the node count from 15 to 30 only halves the error, rather than reducing it by orders of magnitude as it would for a smooth function.</p> <p>Interpolating \\(|x|\\) on \\([-1, 1]\\)</p> <p>With global Chebyshev interpolation, the error near \\(x = 0\\) plateaus at approximately \\(0.01\\) regardless of whether you use 10, 20, or 40 nodes. This is exactly the algebraic \\(O(1/n^2)\\) convergence rate -- the spectral advantage of Chebyshev is lost.</p> <p>In quantitative finance this problem is ubiquitous: option payoffs have kinks at strike prices, barrier levels, and exercise boundaries.  Applying global Chebyshev interpolation to such functions wastes nodes fighting the Gibbs oscillations instead of refining the smooth parts of the function.</p>"},{"location":"user-guide/spline/#why-piecewise-chebyshev-restores-spectral-convergence","title":"Why Piecewise Chebyshev Restores Spectral Convergence","text":"<p>The key to understanding why piecewise interpolation helps lies in the Bernstein ellipse theorem.</p>"},{"location":"user-guide/spline/#the-bernstein-ellipse","title":"The Bernstein ellipse","text":"<p>For a function \\(f\\) analytic in the interior of the Bernstein ellipse \\(\\mathcal{E}_\\rho\\) -- the ellipse in the complex plane with foci at \\(\\pm 1\\) and semi-axis sum \\(\\rho &gt; 1\\) -- the Chebyshev interpolation error on \\([-1, 1]\\) with \\(n\\) nodes satisfies:</p> \\[ \\| f - p_n \\|_\\infty \\leq \\frac{2 M}{\\rho^n (\\rho - 1)} \\] <p>where \\(M = \\max_{z \\in \\mathcal{E}_\\rho} |f(z)|\\).  The rate \\(\\rho^{-n}\\) is exponential in \\(n\\) -- this is spectral convergence.</p>"},{"location":"user-guide/spline/#how-kinks-destroy-analyticity","title":"How kinks destroy analyticity","text":"<p>A function with a kink at \\(c\\) is not analytic at \\(c\\).  The Bernstein ellipse cannot extend past the singularity: it collapses to the real interval near \\(c\\), forcing \\(\\rho \\to 1\\) and reducing convergence to algebraic.</p>"},{"location":"user-guide/spline/#how-splitting-restores-it","title":"How splitting restores it","text":"<p>By placing a knot at \\(c\\) and interpolating each sub-interval separately, each piece sees a smooth function:</p> <ul> <li>\\(|x|\\) restricted to \\([-1, 0]\\) is just \\(-x\\), which is entire (analytic   everywhere in \\(\\mathbb{C}\\)).</li> <li>\\(|x|\\) restricted to \\([0, 1]\\) is just \\(x\\), also entire.</li> </ul> <p>Each piece has a large Bernstein ellipse parameter \\(\\rho_k \\gg 1\\), and the error on piece \\(k\\) with \\(n\\) Chebyshev nodes is:</p> \\[ E_k \\leq \\frac{2 M_k}{\\rho_k^n (\\rho_k - 1)} \\] <p>where \\(M_k = \\max_{z \\in \\mathcal{E}_{\\rho_k}} |f(z)|\\) on that piece's Bernstein ellipse.  Because pieces cover disjoint sub-domains, the overall interpolation error is:</p> \\[ \\| f - \\mathcal{S}_n f \\|_\\infty = \\max_k \\, E_k \\] <p>This is exponential in \\(n\\) -- spectral convergence is restored.</p> <p>Book reference</p> <p>The Chebyshev Spline technique is described in Section 3.8 of Ruiz &amp; Zeron (2021), Machine Learning for Risk Calculations, Wiley Finance.  The book demonstrates that pricing a European call near the strike kink requires 95 nodes with global Chebyshev but only 25 nodes (split into two pieces at \\(K\\)) with a Chebyshev spline -- same accuracy, 4x fewer evaluations.</p>"},{"location":"user-guide/spline/#quick-start","title":"Quick Start","text":"<pre><code>import math\nfrom pychebyshev import ChebyshevSpline\n\n# European call payoff max(S - K, 0) * exp(-rT) with kink at K = 100\ndef payoff(x, _):\n    return max(x[0] - 100.0, 0.0) * math.exp(-0.05 * x[1])\n\n# Place a knot at S = 100 (the strike), no knots in the T dimension\nspline = ChebyshevSpline(\n    payoff,\n    num_dimensions=2,\n    domain=[[80, 120], [0.25, 1.0]],\n    n_nodes=[15, 15],\n    knots=[[100.0], []],   # knot at S=K, none in T\n)\nspline.build()\n\n# Evaluate in-the-money\nprice_itm = spline.eval([110.0, 0.5], [0, 0])\n\n# Evaluate out-of-the-money\nprice_otm = spline.eval([90.0, 0.5], [0, 0])\n\n# Delta (dV/dS) on the in-the-money side\ndelta = spline.eval([110.0, 0.5], [1, 0])\n\nprint(spline)\n</code></pre> <p>Output:</p> <pre><code>ChebyshevSpline (2D, built)\n  Nodes:       [15, 15] per piece\n  Knots:       [[100.0], []]\n  Pieces:      2 (2 x 1)\n  Build:       0.012s (450 function evals)\n  Domain:      [80, 120] x [0.25, 1.0]\n  Error est:   1.23e-10\n</code></pre> <p>With global <code>ChebyshevApproximation</code> on the same domain, you would need approximately 95 nodes to achieve similar accuracy.  The spline uses 2 pieces of 15 nodes each (450 total evaluations vs. 9,025).</p>"},{"location":"user-guide/spline/#choosing-knots","title":"Choosing Knots","text":"<p>Place knots at the locations where the function is non-smooth:</p> Singularity type Example Knot location Payoff kink European call \\(\\max(S - K, 0)\\) \\(S = K\\) Barrier level Knock-out option \\(S = B\\) Exercise boundary American option (if known) \\(S = S^*(T)\\) Absolute value \\(\\|x\\|\\) \\(x = 0\\) <p>Guidelines:</p> <ul> <li>Only add knots where the function is non-smooth.  For smooth functions,   knots provide no benefit -- you pay extra build cost for no accuracy gain.</li> <li>More knots = more pieces = more build evaluations.  Each dimension with   \\(k_d\\) interior knots creates \\(k_d + 1\\) sub-intervals.  The total number   of pieces is the Cartesian product \\(\\prod_d (k_d + 1)\\).</li> <li>Knots must be known a priori. <code>ChebyshevSpline</code> does not detect   singularities automatically; you must specify where they are.</li> </ul>"},{"location":"user-guide/spline/#multiple-knots-and-multi-dimensional-problems","title":"Multiple Knots and Multi-Dimensional Problems","text":""},{"location":"user-guide/spline/#multiple-knots-in-one-dimension","title":"Multiple knots in one dimension","text":"<pre><code># Two knots in dimension 0: at x = -1 and x = 1\n# This creates 3 pieces in dimension 0\nspline = ChebyshevSpline(\n    my_func, 1,\n    domain=[[-3, 3]],\n    n_nodes=[15],\n    knots=[[-1.0, 1.0]],\n)\n</code></pre>"},{"location":"user-guide/spline/#multi-dimensional-knots","title":"Multi-dimensional knots","text":"<p>Each dimension has its own independent list of knots.  The total number of pieces is the Cartesian product of per-dimension intervals:</p> <pre><code># 2D: 2 knots in dim 0, 1 knot in dim 1\n# Pieces: (2+1) x (1+1) = 3 x 2 = 6\nspline = ChebyshevSpline(\n    my_func, 2,\n    domain=[[0, 10], [0, 5]],\n    n_nodes=[15, 15],\n    knots=[[3.0, 7.0], [2.5]],\n)\n</code></pre>"},{"location":"user-guide/spline/#no-knots-in-a-dimension","title":"No knots in a dimension","text":"<p>Use an empty list <code>[]</code> for dimensions where the function is smooth:</p> <pre><code># Knot at S = 100 in price dimension, none in time or vol\nspline = ChebyshevSpline(\n    bs_func, 3,\n    domain=[[80, 120], [0.25, 1.0], [0.15, 0.35]],\n    n_nodes=[15, 15, 15],\n    knots=[[100.0], [], []],\n)\n</code></pre>"},{"location":"user-guide/spline/#degenerate-case-no-knots-at-all","title":"Degenerate case: no knots at all","text":"<p>If every dimension has an empty knot list, the spline has exactly one piece and behaves identically to a plain <code>ChebyshevApproximation</code>.</p>"},{"location":"user-guide/spline/#derivatives","title":"Derivatives","text":"<p>Within each piece, derivatives are computed analytically via spectral differentiation matrices -- the same mechanism used by <code>ChebyshevApproximation</code>. No finite differences are needed.</p> <pre><code># First derivative w.r.t. dimension 0\ndfdx0 = spline.eval([110.0, 0.5], [1, 0])\n\n# Second derivative w.r.t. dimension 0\nd2fdx0 = spline.eval([110.0, 0.5], [2, 0])\n\n# Multiple derivatives at once (shared barycentric weights)\nresults = spline.eval_multi(\n    [110.0, 0.5],\n    [\n        [0, 0],  # function value\n        [1, 0],  # dV/dS\n        [2, 0],  # d2V/dS2\n        [0, 1],  # dV/dT\n    ],\n)\n</code></pre>"},{"location":"user-guide/spline/#derivatives-at-knot-boundaries","title":"Derivatives at knot boundaries","text":"<p>Derivatives are not defined at knot boundaries.  At a kink, the left and right polynomial pieces have different derivative values.  Requesting a derivative at a knot raises <code>ValueError</code>:</p> <pre><code># This raises ValueError:\n# \"Derivative w.r.t. dimension 0 is not defined at knot x[0]=100.0\"\nspline.eval([100.0, 0.5], [1, 0])\n\n# Function values are fine at knots:\nspline.eval([100.0, 0.5], [0, 0])  # OK\n</code></pre> <p>Evaluate near the knot instead</p> <p>If you need a derivative near a knot, evaluate slightly to one side: <code>spline.eval([100.001, 0.5], [1, 0])</code> gives the right-side derivative.</p>"},{"location":"user-guide/spline/#error-estimation","title":"Error Estimation","text":"<p><code>error_estimate()</code> returns the maximum error estimate across all pieces:</p> <pre><code>spline.build()\nprint(f\"Error estimate: {spline.error_estimate():.2e}\")\n</code></pre> <p>Since pieces cover disjoint sub-domains, the interpolation error at any point is bounded by the error of the piece containing that point.  The worst-case error is therefore the maximum over all pieces:</p> \\[ \\hat{E} = \\max_k \\hat{E}_k \\] <p>This differs from <code>ChebyshevSlider</code>, where all slides contribute to every point and the error estimate is the sum over slides.</p>"},{"location":"user-guide/spline/#when-to-use-chebyshevspline","title":"When to Use ChebyshevSpline","text":"Scenario Recommended class Why Smooth function, \\(\\leq\\) 5D <code>ChebyshevApproximation</code> Full tensor is feasible; spectral convergence without knots Function with kinks at known locations <code>ChebyshevSpline</code> Restores spectral convergence by splitting at singularities High-dimensional (\\(5+\\)D), general <code>ChebyshevTT</code> TT-Cross builds from \\(O(d \\cdot n \\cdot r^2)\\) evaluations High-dimensional, additively separable <code>ChebyshevSlider</code> Additive decomposition; cheapest build <p>Use <code>ChebyshevSpline</code> when:</p> <ul> <li>The function has known non-smooth points (kinks, discontinuities).</li> <li>The dimension count is low enough for full tensor grids (typically \\(\\leq 5\\)D).</li> <li>You need analytical derivatives (not finite differences).</li> <li>You want spectral accuracy on a function that would otherwise converge slowly.</li> </ul>"},{"location":"user-guide/spline/#batch-evaluation","title":"Batch Evaluation","text":"<p>For evaluating many points at once, <code>eval_batch()</code> vectorises the piece-routing step and groups points by piece:</p> <pre><code>import numpy as np\n\npoints = np.column_stack([\n    np.random.uniform(80, 120, 1000),\n    np.random.uniform(0.25, 1.0, 1000),\n])\nvalues = spline.eval_batch(points, [0, 0])\n</code></pre> <p>Points that fall in the same piece are batched together for efficient evaluation.</p>"},{"location":"user-guide/spline/#serialization","title":"Serialization","text":"<p>Save and load splines using the same pattern as other PyChebyshev classes:</p> <pre><code># Save\nspline.save(\"payoff_spline.pkl\")\n\n# Load (no rebuild needed)\nfrom pychebyshev import ChebyshevSpline\nloaded = ChebyshevSpline.load(\"payoff_spline.pkl\")\nval = loaded.eval([110.0, 0.5], [0, 0])\n</code></pre> <p>The original function is not saved -- only the numerical data needed for evaluation.  Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p>"},{"location":"user-guide/spline/#limitations","title":"Limitations","text":"<ul> <li> <p>Knots must be known a priori. <code>ChebyshevSpline</code> does not automatically   detect singularities.  You must know where the function is non-smooth and place   knots accordingly.</p> </li> <li> <p>Build cost scales with the number of pieces.  Total evaluations are   \\(\\text{num\\_pieces} \\times \\prod_d n_d\\).  Many knots in many dimensions   creates many pieces: 3 knots in each of 4 dimensions means   \\(4^4 = 256\\) pieces.</p> </li> <li> <p>Low-dimensional only.  Like <code>ChebyshevApproximation</code>, each piece requires   a full tensor grid.  For high-dimensional functions with kinks, a future   extension could compose <code>ChebyshevSpline</code> with <code>ChebyshevTT</code> or   <code>ChebyshevSlider</code>.</p> </li> </ul>"},{"location":"user-guide/spline/#api-reference","title":"API Reference","text":"<p>Piecewise Chebyshev interpolation with user-specified knots.</p> <p>Partitions the domain into sub-intervals at interior knots and builds an independent :class:<code>ChebyshevApproximation</code> on each piece.  Query points are routed to the appropriate piece for evaluation.</p> <p>This is the correct approach when the target function has known singularities (kinks, discontinuities) at specific locations: place knots at those locations so that each piece is smooth, restoring spectral convergence.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate.  Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [lo, hi] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension per piece.</p> required <code>knots</code> <code>list of list of float</code> <p>Interior knots for each dimension.  Each sub-list must be sorted and every knot must lie strictly inside the corresponding domain interval.  Use an empty list <code>[]</code> for dimensions with no knots.</p> required <code>max_derivative_order</code> <code>int</code> <p>Maximum derivative order to pre-compute (default 2).</p> <code>2</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return abs(x[0])\n&gt;&gt;&gt; sp = ChebyshevSpline(f, 1, [[-1, 1]], [15], [[0.0]])\n&gt;&gt;&gt; sp.build(verbose=False)\n&gt;&gt;&gt; round(sp.eval([0.5], [0]), 10)\n0.5\n&gt;&gt;&gt; round(sp.eval([-0.3], [0]), 10)\n0.3\n</code></pre>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.num_pieces","title":"<code>num_pieces</code>  <code>property</code>","text":"<p>Total number of pieces (Cartesian product of per-dimension intervals).</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.total_build_evals","title":"<code>total_build_evals</code>  <code>property</code>","text":"<p>Total number of function evaluations used during build.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.build_time","title":"<code>build_time</code>  <code>property</code>","text":"<p>Wall-clock time (seconds) for the most recent <code>build()</code> call.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.build","title":"<code>build(verbose=True)</code>","text":"<p>Build all pieces by evaluating the function on each sub-domain.</p> <p>Each piece is an independent :class:<code>ChebyshevApproximation</code> built on the Cartesian product of per-dimension sub-intervals.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress.  Default is True.</p> <code>True</code>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.eval","title":"<code>eval(point, derivative_order)</code>","text":"<p>Evaluate the spline approximation at a point.</p> <p>Routes the query to the piece whose sub-domain contains <code>point</code> and delegates to its :meth:<code>~ChebyshevApproximation.vectorized_eval</code>.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full domain.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order for each dimension (0 = function value).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Approximated function value or derivative.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If the point is at a knot and a non-zero derivative is requested.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.eval_multi","title":"<code>eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate multiple derivative orders at one point, sharing weights.</p> <p>Routes to a single piece and delegates to its :meth:<code>~ChebyshevApproximation.vectorized_eval_multi</code> so that barycentric weight computation is shared across all requested derivative orders.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full domain.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension.</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>One result per derivative order.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If the point is at a knot and a non-zero derivative is requested.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.eval_batch","title":"<code>eval_batch(points, derivative_order)</code>","text":"<p>Evaluate at multiple points, grouping by piece for efficiency.</p> <p>Vectorises the piece-routing step using <code>np.searchsorted</code> and evaluates each piece's batch via :meth:<code>~ChebyshevApproximation.vectorized_eval_batch</code>.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray of shape (N, num_dimensions)</code> <p>Evaluation points.</p> required <code>derivative_order</code> <code>list of int</code> <p>Derivative order for each dimension.</p> required <p>Returns:</p> Type Description <code>ndarray of shape (N,)</code> <p>Approximated values or derivatives at each point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate the supremum-norm interpolation error.</p> <p>Returns the maximum error estimate across all pieces.  Since pieces cover disjoint sub-domains, the interpolation error at any point is bounded by the error of the piece containing that point. The worst-case error is therefore the maximum over all pieces (not the sum, unlike :class:<code>ChebyshevSlider</code> where all slides contribute to every point).</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated maximum interpolation error (sup-norm).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state from a pickled dict.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.save","title":"<code>save(path)</code>","text":"<p>Save the built spline to a file.</p> <p>The original function is not saved -- only the numerical data needed for evaluation.  The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the spline has not been built yet.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved spline from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>.  Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevSpline</code> <p>The restored spline.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally.  Pickle can execute arbitrary code during deserialization.  Only load files you trust.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.extrude","title":"<code>extrude(params)</code>","text":"<p>Add new dimensions where the function is constant.</p> <p>Each piece is extruded independently via :meth:<code>ChebyshevApproximation.extrude</code>.  The extruded spline evaluates identically to the original regardless of the new coordinate(s), because Chebyshev basis functions form a partition of unity.  The new dimension gets <code>knots=[]</code> and a single interval <code>(lo, hi)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, (lo, hi), n_nodes)</code> or a list of such tuples.  <code>dim_index</code> is the position in the output space (0-indexed).  <code>n_nodes</code> must be &gt;= 2 and <code>lo &lt; hi</code>.</p> required <p>Returns:</p> Type Description <code>ChebyshevSpline</code> <p>A new, higher-dimensional spline (already built). The result has <code>function=None</code> and <code>build_time=0.0</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the spline has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If <code>dim_index</code> is out of range, duplicated, <code>lo &gt;= hi</code>, or <code>n_nodes &lt; 2</code>.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.slice","title":"<code>slice(params)</code>","text":"<p>Fix one or more dimensions at given values, reducing dimensionality.</p> <p>For each sliced dimension, only the pieces whose interval contains the slice value survive.  Each surviving piece is then sliced via :meth:<code>ChebyshevApproximation.slice</code>, which contracts the tensor along that axis using the barycentric interpolation formula.  When the slice value coincides with a Chebyshev node (within 1e-14), the contraction reduces to an exact <code>np.take</code> (fast path).</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple or list of tuples</code> <p>Single <code>(dim_index, value)</code> or a list of such tuples. <code>value</code> must lie within the domain for that dimension.</p> required <p>Returns:</p> Type Description <code>ChebyshevSpline</code> <p>A new, lower-dimensional spline (already built). The result has <code>function=None</code> and <code>build_time=0.0</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the spline has not been built yet.</p> <code>TypeError</code> <p>If <code>dim_index</code> is not an integer.</p> <code>ValueError</code> <p>If a slice value is outside the domain, if slicing all dimensions, or if <code>dim_index</code> is out of range or duplicated.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.integrate","title":"<code>integrate(dims=None)</code>","text":"<p>Integrate the spline over one or more dimensions.</p> <p>For full integration, sums the integrals of each piece (pieces cover disjoint sub-domains).  For partial integration, pieces along the integrated dimension are summed and the result is a lower-dimensional spline.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>int, list of int, or None</code> <p>Dimensions to integrate out.  If <code>None</code>, integrates over all dimensions and returns a scalar.</p> <code>None</code> <p>Returns:</p> Type Description <code>float or ChebyshevSpline</code> <p>Scalar for full integration; lower-dimensional spline for partial integration.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If any dimension index is out of range or duplicated.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.roots","title":"<code>roots(dim=None, fixed=None)</code>","text":"<p>Find all roots of the spline along a specified dimension.</p> <p>Slices the spline to 1-D, then finds roots in each piece and merges the results.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to find roots.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted array of root locations in the physical domain.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.minimize","title":"<code>minimize(dim=None, fixed=None)</code>","text":"<p>Find the minimum value of the spline along a dimension.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to minimize.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>(value, location) : (float, float)</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p>"},{"location":"user-guide/spline/#pychebyshev.spline.ChebyshevSpline.maximize","title":"<code>maximize(dim=None, fixed=None)</code>","text":"<p>Find the maximum value of the spline along a dimension.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int or None</code> <p>Dimension along which to maximize.</p> <code>None</code> <code>fixed</code> <code>dict or None</code> <p>For multi-D, dict <code>{dim_index: value}</code> for all other dims.</p> <code>None</code> <p>Returns:</p> Type Description <code>(value, location) : (float, float)</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p> <code>ValueError</code> <p>If dim / fixed validation fails.</p>"},{"location":"user-guide/tensor-train/","title":"Tensor Train Interpolation","text":""},{"location":"user-guide/tensor-train/#introduction","title":"Introduction","text":"<p>The Tensor Train (TT) format enables Chebyshev interpolation of functions with 5 or more dimensions by decomposing the full coefficient tensor into a chain of small 3D cores. Instead of storing and building the full \\(n^d\\) tensor (infeasible for \\(d \\geq 6\\)), TT stores \\(O(d \\cdot n \\cdot r^2)\\) elements, where \\(r\\) is the TT rank -- a measure of the function's internal complexity.</p>"},{"location":"user-guide/tensor-train/#when-to-use-which-class","title":"When to use which class","text":"Scenario Class Why \\(d \\leq 5\\) <code>ChebyshevApproximation</code> Full tensor is feasible; analytical derivatives \\(d \\geq 5\\), general function <code>ChebyshevTT</code> TT-Cross builds from \\(O(d \\cdot n \\cdot r^2)\\) evaluations \\(d \\gg 5\\), separable function <code>ChebyshevSlider</code> Additive decomposition; cheapest build, but loses cross-group coupling <p><code>ChebyshevTT</code> fills the gap between the full tensor approach (limited to low dimensions) and the sliding technique (limited to separable functions). It handles general functions -- including those with strong multiplicative coupling like Black-Scholes -- at a fraction of the full tensor cost.</p>"},{"location":"user-guide/tensor-train/#quick-start","title":"Quick Start","text":"<pre><code>import math\nfrom scipy.stats import norm\nfrom pychebyshev import ChebyshevTT\n\ndef black_scholes_5d(x, _):\n    \"\"\"European call price: V(S, K, T, sigma, r).\"\"\"\n    S, K, T, sigma, r = x\n    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * math.sqrt(T))\n    d2 = d1 - sigma * math.sqrt(T)\n    return S * norm.cdf(d1) - K * math.exp(-r * T) * norm.cdf(d2)\n\ntt = ChebyshevTT(\n    black_scholes_5d, 5,\n    domain=[[80, 120], [90, 110], [0.25, 1.0], [0.15, 0.35], [0.01, 0.08]],\n    n_nodes=[11, 11, 11, 11, 11],\n    max_rank=15,\n)\ntt.build()\nprice = tt.eval([100, 100, 1.0, 0.25, 0.05])\nprint(f\"TT price: {price:.6f}\")\n</code></pre> <p>After building, <code>print(tt)</code> shows a summary including TT ranks and compression ratio:</p> <pre><code>ChebyshevTT (5D, built)\n  Nodes:       [11, 11, 11, 11, 11]\n  TT ranks:    [1, 11, 11, 11, 7, 1]\n  Compression: 161,051 -&gt; 3,707 elements (43.4x)\n  Build:       0.351s (7,419 function evals)\n  Domain:      [80, 120] x [90, 110] x [0.25, 1.0] x [0.15, 0.35] x [0.01, 0.08]\n  Error est:   1.23e-06\n</code></pre>"},{"location":"user-guide/tensor-train/#how-it-works","title":"How It Works","text":""},{"location":"user-guide/tensor-train/#tt-format","title":"TT format","text":"<p>A \\(d\\)-dimensional tensor \\(\\mathcal{A}\\) with indices \\(j_1, \\ldots, j_d\\) is represented as a chain of 3D cores:</p> \\[\\mathcal{A}(j_1, \\ldots, j_d) = G_1(j_1) \\cdot G_2(j_2) \\cdots G_d(j_d)\\] <p>Each core \\(G_k\\) is a 3D array of shape \\((r_{k-1}, n_k, r_k)\\), and for a fixed index \\(j_k\\) the slice \\(G_k(j_k)\\) is an \\(r_{k-1} \\times r_k\\) matrix. The product of these matrices yields the tensor element. The boundary ranks are \\(r_0 = r_d = 1\\), so the result is a scalar.</p> <p>Storage: The full tensor has \\(\\prod_k n_k\\) elements. The TT format stores \\(\\sum_k r_{k-1} \\cdot n_k \\cdot r_k\\) elements -- exponentially smaller when ranks are moderate.</p>"},{"location":"user-guide/tensor-train/#tt-cross-build-algorithm","title":"TT-Cross build algorithm","text":"<p>The key advantage of <code>ChebyshevTT</code> over full tensor interpolation is how it is built. Instead of evaluating the function at every node combination (\\(n^d\\) points), the TT-Cross algorithm (Oseledets &amp; Tyrtyshnikov 2010) evaluates at strategically selected grid points. For 5D with \\(n = 11\\) and <code>max_rank=15</code>:</p> <ul> <li>Full tensor: 161,051 evaluations</li> <li>TT-Cross: ~7,400 unique evaluations (21.7x fewer)</li> </ul> <p>The algorithm performs alternating sweeps:</p> <p>1. Initialize. Randomly select multi-index sets \\(J_{\\text{right}}[k]\\) for each dimension, each containing \\(r_k\\) multi-indices into the \"right\" dimensions \\(k+1, \\ldots, d-1\\).</p> <p>2. Left-to-right sweep. For each dimension \\(k = 0, \\ldots, d-2\\):</p> <ul> <li> <p>Build a cross matrix \\(C\\) of shape \\((r_{k-1} \\cdot n_k, r_k)\\).   Each row corresponds to a (left multi-index, node index) pair, and each   column to a right multi-index. Each entry is a function evaluation at   the combined grid point. This is the most expensive step -- it evaluates   the function at \\(r_{k-1} \\cdot n_k \\cdot r_k\\) grid points (with caching,   many of these are free on subsequent sweeps).</p> </li> <li> <p>SVD for rank selection. Compute \\(C = U \\Sigma V^T\\) and determine the   effective rank by counting singular values above a tight threshold   (\\(10^{-12} \\cdot \\sigma_{\\max}\\)). This is further capped by the per-mode   rank bound (see Optimizations below).</p> </li> <li> <p>Maxvol pivot selection. Apply the maxvol algorithm to the left   singular vectors \\(U\\) to select the \\(r\\) rows whose submatrix has   approximately maximal determinant. These pivots identify the most   \"informative\" (left, node) index pairs.</p> </li> <li> <p>Form the TT core via cross interpolation:   \\(\\hat{C} = U \\cdot U[\\text{pivots}]^{-1}\\), then reshape to   \\((r_{k-1}, n_k, r_k)\\). The identity \\(\\hat{C}[\\text{pivots}] = I\\)   ensures exact interpolation at the selected cross points.</p> </li> <li> <p>Update left index set for dimension \\(k+1\\) by expanding each   pivot into its constituent (left multi-index, node index) pair.</p> </li> </ul> <p>3. Convergence check. After completing the L\\(\\to\\)R sweep, evaluate the TT at 20 random grid points and compare against exact function values. If the relative error is below <code>tolerance</code>, stop immediately (skipping the R\\(\\to\\)L sweep).</p> <p>4. Right-to-left sweep. Analogous to L\\(\\to\\)R but processes dimensions from \\(d-1\\) down to 1. The transposed cross matrix \\(C^T\\) is used, and the maxvol pivots update the right index sets.</p> <p>5. Convergence and plateau check. After the R\\(\\to\\)L sweep, evaluate error again. The algorithm tracks the best cores seen across all checks (see Best-cores tracking) and stops if no improvement has been observed for 3 consecutive checks.</p> <p>6. Repeat sweeps until converged, stale, or <code>max_sweeps</code> is reached.</p>"},{"location":"user-guide/tensor-train/#maxvol-algorithm","title":"Maxvol algorithm","text":"<p>The maximum-volume (maxvol) algorithm is a key subroutine within TT-Cross. Given a tall matrix \\(A\\) of shape \\((m, r)\\) with \\(m \\geq r\\), it finds \\(r\\) row indices such that the submatrix \\(A[\\text{idx}]\\) has approximately maximal \\(|\\det|\\).</p> <p>Why maximum volume? The cross interpolation formula \\(\\hat{C} = A \\cdot A[\\text{idx}]^{-1}\\) requires inverting the \\(r \\times r\\) submatrix \\(A[\\text{idx}]\\). A near-singular submatrix (small determinant) would amplify errors in this inversion, producing inaccurate TT cores. Maximizing \\(|\\det(A[\\text{idx}])|\\) is equivalent to selecting the \\(r\\) most linearly independent rows of \\(A\\) -- this minimizes the condition number of the inversion and ensures numerically stable cross interpolation.</p> <p>In the context of TT-Cross, each row of \\(A\\) corresponds to a particular grid point (a combination of left multi-index and Chebyshev node). Maxvol therefore selects the grid points that carry the most \"information\" about the function, avoiding redundant or nearly-collinear samples.</p> <p>The implementation uses two phases:</p> <ol> <li> <p>Initialization via column-pivoted QR. Compute    <code>Q, R, piv = qr(A.T, pivoting=True)</code>. The first \\(r\\) pivot indices    identify the \\(r\\) most linearly independent rows of \\(A\\) -- a good    starting point.</p> </li> <li> <p>Iterative refinement. Compute the coefficient matrix    \\(B = A \\cdot A[\\text{idx}]^{-1}\\) (shape \\(m \\times r\\)). While    \\(\\max|B_{ij}| &gt; 1.05\\):</p> <ul> <li>Find the entry \\((i, j)\\) with largest \\(|B_{ij}|\\).</li> <li>Swap: replace row \\(j\\) in the index set with row \\(i\\).</li> <li>Rank-1 update of \\(B\\) (avoids re-inverting the full matrix).</li> </ul> </li> </ol> <p>Each swap strictly increases \\(|\\det(A[\\text{idx}])|\\), and the algorithm converges in \\(O(r^2)\\) iterations in practice.</p>"},{"location":"user-guide/tensor-train/#coefficient-conversion","title":"Coefficient conversion","text":"<p>After TT-Cross produces cores containing function values at Chebyshev nodes, a DCT-II is applied along the middle axis of each core to convert from function values to Chebyshev expansion coefficients:</p> <pre><code>from scipy.fft import dct\n\n# core shape: (r_{k-1}, n_k, r_k)\ncoeff_core = dct(core[:, ::-1, :], type=2, axis=1) / n_k\ncoeff_core[:, 0, :] /= 2\n</code></pre> <p>The reversal (<code>::-1</code>) converts from ascending to descending node order, which is the convention expected by the DCT-II. The division by \\(n_k\\) normalizes the transform, and halving the zeroth coefficient accounts for the Chebyshev series convention (\\(\\frac{c_0}{2} T_0 + c_1 T_1 + \\cdots\\)). See Error Estimation: Computing coefficients via DCT-II for the mathematical justification.</p>"},{"location":"user-guide/tensor-train/#evaluation-via-tt-inner-product","title":"Evaluation via TT inner product","text":"<p>Given the pre-computed coefficient cores \\(\\mathcal{C}\\) and a query point \\(p\\), evaluation computes the inner product:</p> \\[I(p) = \\langle \\mathcal{C},\\, \\mathcal{T}_p \\rangle\\] <p>where \\(\\mathcal{T}_p\\) is a rank-1 tensor whose entries are Chebyshev polynomial values \\([T_0(\\tilde{x}_k), T_1(\\tilde{x}_k), \\ldots, T_{n_k-1}(\\tilde{x}_k)]\\) at the scaled query coordinate \\(\\tilde{x}_k\\) in each dimension \\(k\\).</p> <p>In practice, this inner product is computed as a chain of matrix contractions:</p> <pre><code>result = np.ones((1, 1))\nfor k in range(num_dims):\n    q = chebyshev_polynomials(scaled_x[k], n_nodes[k])   # (n_k,)\n    v = np.einsum('j,ijk-&gt;ik', q, coeff_cores[k])        # (r_{k-1}, r_k)\n    result = result @ v\nvalue = result[0, 0]\n</code></pre> <p>Each step contracts one dimension, reducing the chain until a scalar remains. The cost is \\(O(d \\cdot n \\cdot r^2)\\) per point.</p>"},{"location":"user-guide/tensor-train/#optimizations","title":"Optimizations","text":"<p>PyChebyshev's TT-Cross implementation includes several optimizations that reduce function evaluations by 10--20x compared to a naive implementation.</p>"},{"location":"user-guide/tensor-train/#eval-caching","title":"Eval caching","text":"<p>Function evaluations are cached in a dictionary keyed by the grid index tuple. When the same grid point is needed again -- whether during the R\\(\\to\\)L sweep of the same iteration, or in subsequent sweeps -- the cached value is returned instantly. This is the single largest optimization: for 5D Black-Scholes with <code>max_rank=15</code>, caching reduces evaluations from ~85,000 to ~7,400.</p>"},{"location":"user-guide/tensor-train/#per-mode-rank-caps","title":"Per-mode rank caps","text":"<p>At bond \\(k\\), the theoretical maximum TT rank is \\(\\min(\\prod_{i&lt;k} n_i,\\; \\prod_{i \\geq k} n_i)\\). For example, with 5 dimensions of 11 nodes each, the first bond can have rank at most \\(\\min(11, 14641) = 11\\). PyChebyshev automatically caps the rank at each bond to this theoretical limit, preventing the algorithm from attempting ranks that are mathematically impossible.</p>"},{"location":"user-guide/tensor-train/#svd-based-adaptive-rank","title":"SVD-based adaptive rank","text":"<p>Instead of always using <code>max_rank</code> columns from a QR decomposition, the cross matrix is decomposed via SVD. Singular values below \\(10^{-12} \\cdot \\sigma_{\\max}\\) are dropped, so dimensions where the function has low effective rank naturally get smaller cores. For the 5D Black-Scholes example, this produces adaptive ranks <code>[1, 11, 11, 11, 7, 1]</code> instead of a uniform <code>[1, 11, 11, 11, 11, 1]</code> -- the last bond only needs rank 7 because the interest rate dimension has simpler structure.</p>"},{"location":"user-guide/tensor-train/#half-sweep-convergence","title":"Half-sweep convergence","text":"<p>Error is checked after the L\\(\\to\\)R half-sweep. If the TT already reproduces the function to within <code>tolerance</code> at random test points, the R\\(\\to\\)L sweep is skipped entirely. For separable functions like \\(\\sin(x) + \\sin(y) + \\sin(z)\\), this means convergence in a single L\\(\\to\\)R pass with only 159 evaluations.</p>"},{"location":"user-guide/tensor-train/#best-cores-tracking","title":"Best-cores tracking","text":"<p>TT-Cross error can oscillate between L\\(\\to\\)R and R\\(\\to\\)L sweeps -- a good L\\(\\to\\)R result may be partially degraded by R\\(\\to\\)L rebalancing. PyChebyshev keeps a copy of the best cores (lowest error) seen across all convergence checks, and returns those when the algorithm stops. This prevents the final result from being worse than an intermediate result.</p> <p>The algorithm also counts \"stale checks\" -- consecutive convergence checks that fail to improve the best error by at least 10%. After 3 stale checks (and best error below \\(10^{-3}\\)), the algorithm stops early, returning the best cores found.</p>"},{"location":"user-guide/tensor-train/#tt-svd-validation-build","title":"TT-SVD (validation build)","text":"<p>For moderate dimensions (\\(d \\leq 6\\)), the <code>method='svd'</code> option builds the full tensor and decomposes it via sequential truncated SVD. This produces optimal TT ranks (up to the SVD truncation tolerance) and is useful for:</p> <ul> <li>Validating TT-Cross accuracy against the best possible TT decomposition.</li> <li>Confirming that the function's intrinsic TT rank structure matches   expectations.</li> <li>Problems where the function is cheap to evaluate and a full tensor build   is acceptable.</li> </ul> <pre><code># TT-SVD \u2014 for validation or moderate dimensions\ntt.build(method=\"svd\")\n</code></pre> <p>In TT-SVD, singular values below <code>tolerance * sigma_max</code> are discarded at each unfolding. For a separable function like \\(\\sin(x) + \\sin(y) + \\sin(z)\\), TT-SVD finds exact rank <code>[1, 2, 2, 1]</code>.</p>"},{"location":"user-guide/tensor-train/#controlling-accuracy","title":"Controlling Accuracy","text":""},{"location":"user-guide/tensor-train/#max_rank","title":"<code>max_rank</code>","text":"<p>The TT rank controls how much \"coupling\" between dimensions the approximation can capture. Higher rank means more accurate, but more expensive to build and store.</p> <code>max_rank</code> Typical use 5--10 Smooth, nearly separable functions 10--15 General smooth functions (e.g., Black-Scholes) 20--30 Functions with strong nonlinear coupling <p>Start low, increase if needed</p> <p>Begin with <code>max_rank=10</code> and check <code>error_estimate()</code>. If the error is too large, increase to 15 or 20. Smooth functions like Black-Scholes options typically converge well with ranks of 5--15.</p> <p>The table below shows how <code>max_rank</code> affects the 5D Black-Scholes approximation (11 nodes per dimension, <code>seed=42</code>):</p> <code>max_rank</code> Unique evals Max price error TT ranks 8 ~4,500 0.58% [1, 8, 8, 8, 6, 1] 10 ~7,500 0.09% [1, 10, 10, 10, 7, 1] 15 ~7,400 0.19% [1, 11, 11, 11, 7, 1] <p>Note that <code>max_rank=15</code> and <code>max_rank=10</code> use a similar number of evaluations because per-mode rank caps limit interior ranks to at most \\(n = 11\\).</p>"},{"location":"user-guide/tensor-train/#tolerance","title":"<code>tolerance</code>","text":"<p>The convergence tolerance for TT-Cross. The algorithm checks relative error at random grid points after each half-sweep. When the error drops below this threshold, iteration stops. The default <code>1e-6</code> is appropriate for most problems.</p> <p>Tolerance does not control SVD truncation</p> <p>The <code>tolerance</code> parameter only controls when the sweep loop stops. Rank selection within each mode uses a fixed threshold of \\(10^{-12}\\) to drop only numerically zero singular values. Rank is primarily controlled by <code>max_rank</code> and the per-mode caps.</p>"},{"location":"user-guide/tensor-train/#max_sweeps","title":"<code>max_sweeps</code>","text":"<p>The maximum number of alternating left-right sweeps. The default of 10 is sufficient for most well-behaved functions. In practice, the best-cores tracking and stale-check stopping mean the algorithm often finishes in 2--3 sweeps.</p>"},{"location":"user-guide/tensor-train/#build-method","title":"Build method","text":"<p>The <code>build()</code> method accepts a <code>method</code> parameter:</p> <ul> <li><code>method='cross'</code> (default): TT-Cross algorithm -- evaluates only   \\(O(d \\cdot n \\cdot r^2)\\) points. Use for high-dimensional problems.</li> <li><code>method='svd'</code>: Builds the full tensor and decomposes via truncated SVD.   Only feasible for moderate dimensions (\\(d \\leq 6\\)), but produces optimal   ranks and is useful for validation.</li> </ul> <pre><code># TT-Cross (default) \u2014 efficient for high dimensions\ntt.build(method=\"cross\", seed=42)\n\n# TT-SVD \u2014 for validation or moderate dimensions\ntt.build(method=\"svd\")\n</code></pre>"},{"location":"user-guide/tensor-train/#error-estimation","title":"Error estimation","text":"<p>Like <code>ChebyshevApproximation</code>, the TT class supports ex ante error estimation from its coefficient cores:</p> <pre><code>tt.build()\nprint(f\"Estimated error: {tt.error_estimate():.2e}\")\n</code></pre> <p>Approximate for TT</p> <p>The TT error estimate is based on the trailing Chebyshev coefficients within each core. It captures per-core truncation error but does not account for rank truncation error. The true error may be somewhat larger than the estimate, especially at low ranks.</p>"},{"location":"user-guide/tensor-train/#derivatives-via-finite-differences","title":"Derivatives via Finite Differences","text":"<p>The TT format does not support analytical derivatives (the spectral differentiation matrix approach used by <code>ChebyshevApproximation</code> requires the full tensor). Instead, <code>ChebyshevTT</code> computes derivatives via central finite differences:</p> \\[\\frac{\\partial f}{\\partial x_k} \\approx \\frac{f(x + h\\, e_k) - f(x - h\\, e_k)}{2h}\\] <p>The <code>eval_multi()</code> method computes price and Greeks in a single call:</p> <pre><code>point = [100, 100, 1.0, 0.25, 0.05]\n\nresults = tt.eval_multi(point, [\n    [0, 0, 0, 0, 0],  # price\n    [1, 0, 0, 0, 0],  # Delta (dV/dS)\n    [2, 0, 0, 0, 0],  # Gamma (d\u00b2V/dS\u00b2)\n    [0, 0, 0, 1, 0],  # Vega  (dV/dsigma)\n    [0, 0, 0, 0, 1],  # Rho   (dV/dr)\n])\nprice, delta, gamma, vega, rho = results\n</code></pre> <p>The step size \\(h\\) is chosen automatically as \\(10^{-4}\\) times the domain width in each dimension. Points near domain boundaries are nudged inward to ensure the FD stencil stays inside the domain.</p> <p>FD accuracy</p> <p>For first-order derivatives, accuracy is typically within a few hundredths of a percent of the analytical value. Second-order derivatives (e.g., Gamma) are less precise due to the inherent amplification of noise in central second differences.</p>"},{"location":"user-guide/tensor-train/#batch-evaluation","title":"Batch Evaluation","text":"<p>For evaluating many points at once -- common in portfolio pricing -- use <code>eval_batch()</code>:</p> <pre><code>import numpy as np\n\n# 1000 random points in the domain\npoints = np.column_stack([\n    np.random.uniform(80, 120, 1000),    # S\n    np.random.uniform(90, 110, 1000),    # K\n    np.random.uniform(0.25, 1.0, 1000),  # T\n    np.random.uniform(0.15, 0.35, 1000), # sigma\n    np.random.uniform(0.01, 0.08, 1000), # r\n])\n\nprices = tt.eval_batch(points)  # (1000,) array\n</code></pre> <p><code>eval_batch()</code> vectorizes the TT inner product over all points simultaneously using <code>np.einsum</code> for batched matrix contractions, which is significantly faster than calling <code>eval()</code> in a loop. Typical speedup is 15--20x.</p>"},{"location":"user-guide/tensor-train/#performance-comparison","title":"Performance Comparison","text":""},{"location":"user-guide/tensor-train/#pychebyshev-vs-mocax-extend-tensor-train","title":"PyChebyshev vs MoCaX Extend (Tensor Train)","text":"<p>Both PyChebyshev <code>ChebyshevTT</code> and MoCaX <code>MocaxExtend</code> build Chebyshev interpolants in Tensor Train format. They differ in how the TT is constructed:</p> PyChebyshev <code>ChebyshevTT</code> MoCaX <code>MocaxExtend</code> Build algorithm TT-Cross (maxvol pivoting) Rank-adaptive ALS on random subgrid Point selection Adaptive via cross interpolation Random subset of full Chebyshev grid Eval implementation Vectorized NumPy (einsum, BLAS) Python loops + deep copies Coefficient cores Pre-computed via DCT-II Recomputed on every eval call <p>The following benchmarks are from 5D Black-Scholes \\(V(S, K, T, \\sigma, r)\\) with 11 Chebyshev nodes per dimension, dividend yield \\(q = 0.02\\).</p>"},{"location":"user-guide/tensor-train/#build-comparison","title":"Build comparison","text":"Metric PyChebyshev MoCaX Build time 0.35s 5.73s Function evaluations 7,419 8,000 <p>PyChebyshev uses slightly fewer evaluations (TT-Cross adaptively selects the most informative points) and builds 16x faster (no Python-level ALS optimization loop).</p>"},{"location":"user-guide/tensor-train/#accuracy-50-random-test-points","title":"Accuracy (50 random test points)","text":"Metric PyChebyshev MoCaX Mean price error 0.002% 0.093% Max price error 0.014% 0.712% Median price error 0.001% 0.045% <p>PyChebyshev is 40--50x more accurate at comparable evaluation budgets.</p>"},{"location":"user-guide/tensor-train/#evaluation-speed-1000-random-points","title":"Evaluation speed (1000 random points)","text":"Method PyChebyshev MoCaX Single eval 0.065 ms/query -- Batch eval 0.004 ms/query 0.246 ms/query <p>PyChebyshev batch evaluation is 58x faster than MoCaX.</p>"},{"location":"user-guide/tensor-train/#greeks-accuracy-10-scenarios-vs-analytical","title":"Greeks accuracy (10 scenarios vs analytical)","text":"Greek PyChebyshev avg error MoCaX avg error Delta 0.029% 0.379% Gamma 0.019% 1.604% <p>Both use central finite differences. PyChebyshev's advantage comes from its more accurate underlying interpolant.</p>"},{"location":"user-guide/tensor-train/#reproducing-the-comparison","title":"Reproducing the comparison","text":"<p>The comparison script <code>compare_tensor_train.py</code> in the repository root runs all the benchmarks above. It requires the MoCaX C++ library (not publicly available); PyChebyshev results are shown regardless.</p> <pre><code># Run the comparison (MoCaX portion is skipped if unavailable)\nuv run --with tqdm --with blackscholes python compare_tensor_train.py\n</code></pre> <p>If you have MoCaX installed, ensure the <code>mocaxextend_lib/</code> directory with <code>shared_libs/</code> (containing <code>libtensorvals.so</code> and <code>libhommat.so</code>) is in the repository root.</p> <p>MoCaX results are nondeterministic</p> <p>MoCaX uses a random subgrid for its ALS optimization, so its accuracy varies between runs. The numbers above are representative of typical runs.</p>"},{"location":"user-guide/tensor-train/#comparison-with-other-pychebyshev-methods","title":"Comparison with Other PyChebyshev Methods","text":"<code>ChebyshevApproximation</code> <code>ChebyshevTT</code> <code>ChebyshevSlider</code> Dimensions \\(\\leq 5\\) (practical) \\(5+\\) Any (with caveats) Build cost \\(O(n^d)\\) evaluations \\(O(d \\cdot n \\cdot r^2)\\) evaluations $\\sum_i O(n_{g_i}^{ Eval cost \\(O(d \\cdot n)\\) via BLAS GEMV \\(O(d \\cdot n \\cdot r^2)\\) via einsum \\(O(k \\cdot d_g \\cdot n)\\) per slide Derivatives Analytical (spectral) Finite differences Analytical (per-slide) Accuracy Spectral convergence Rank-dependent Depends on separability Best for Low-\\(d\\), high-accuracy Greeks Moderate-\\(d\\), general functions High-\\(d\\), separable functions"},{"location":"user-guide/tensor-train/#serialization","title":"Serialization","text":"<p><code>ChebyshevTT</code> supports saving and loading via pickle, following the same pattern as the other PyChebyshev classes:</p> <pre><code># Save after building\ntt.save(\"bs_5d_tt.pkl\")\n\n# Load later (no rebuild needed)\nfrom pychebyshev import ChebyshevTT\ntt_loaded = ChebyshevTT.load(\"bs_5d_tt.pkl\")\nprice = tt_loaded.eval([100, 100, 1.0, 0.25, 0.05])\n</code></pre> <p>Note</p> <p>The original function is not saved -- only the pre-computed coefficient cores and metadata. After loading, <code>eval()</code>, <code>eval_batch()</code>, and <code>eval_multi()</code> work normally, but <code>build()</code> cannot be called again without re-supplying the function.</p>"},{"location":"user-guide/tensor-train/#limitations","title":"Limitations","text":"<ul> <li>No analytical derivatives. The TT format does not support spectral   differentiation matrices. Derivatives are computed via finite differences, which   are less accurate (especially for second-order derivatives like Gamma).</li> <li>Error estimates are approximate. The <code>error_estimate()</code> method captures   per-core coefficient truncation but not rank truncation error. Always validate   against known solutions when possible.</li> <li>Convergence depends on function structure. TT-Cross works best for functions   with low-rank structure (smooth, with moderate coupling between variables). Not   all functions have good low-rank TT approximations -- highly oscillatory or   discontinuous functions may require very high ranks.</li> <li>Build cost grows with rank. While \\(O(d \\cdot n \\cdot r^2)\\) is much better   than \\(O(n^d)\\), a large <code>max_rank</code> (say, 50+) can still be expensive for costly   functions.</li> </ul>"},{"location":"user-guide/tensor-train/#mathematical-reference","title":"Mathematical Reference","text":"<p>The TT interpolation approach implemented here follows:</p> <ul> <li>Ruiz &amp; Zeron (2021), Machine Learning for Risk Calculations, Wiley Finance,   Chapter 6: Tensor Train decomposition for Chebyshev interpolation.</li> <li>Oseledets &amp; Tyrtyshnikov (2010), \"TT-Cross approximation for multidimensional   arrays\" -- the cross approximation algorithm used to build TT cores from function   evaluations.</li> <li>Goreinov, Tyrtyshnikov &amp; Zamarashkin (1997) -- maxvol algorithm for pivot   selection within TT-Cross.</li> </ul>"},{"location":"user-guide/tensor-train/#api-reference","title":"API Reference","text":"<p>Chebyshev interpolation in Tensor Train format.</p> <p>For functions of 5+ dimensions where full tensor interpolation is infeasible. Uses TT-Cross to build from O(d * n * r^2) function evaluations instead of O(n^d), then evaluates via TT inner product.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>callable</code> <p>Function to approximate. Signature: <code>f(point, data) -&gt; float</code> where <code>point</code> is a list of floats and <code>data</code> is arbitrary additional data (can be None).</p> required <code>num_dimensions</code> <code>int</code> <p>Number of input dimensions.</p> required <code>domain</code> <code>list of (float, float)</code> <p>Bounds [(lo, hi), ...] for each dimension.</p> required <code>n_nodes</code> <code>list of int</code> <p>Number of Chebyshev nodes per dimension.</p> required <code>max_rank</code> <code>int</code> <p>Maximum TT rank. Higher = more accurate, more expensive. Default is 10.</p> <code>10</code> <code>tolerance</code> <code>float</code> <p>Convergence tolerance for TT-Cross. Default is 1e-6.</p> <code>1e-06</code> <code>max_sweeps</code> <code>int</code> <p>Maximum number of TT-Cross sweeps. Default is 10.</p> <code>10</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import math\n&gt;&gt;&gt; def f(x, _):\n...     return math.sin(x[0]) + math.sin(x[1]) + math.sin(x[2])\n&gt;&gt;&gt; tt = ChebyshevTT(f, 3, [[-1, 1], [-1, 1], [-1, 1]], [11, 11, 11])\n&gt;&gt;&gt; tt.build(verbose=False)\n&gt;&gt;&gt; tt.eval([0.5, 0.3, 0.1])\n0.8764...\n</code></pre>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.tt_ranks","title":"<code>tt_ranks</code>  <code>property</code>","text":"<p>TT ranks [1, r_1, r_2, ..., r_{d-1}, 1].</p> <p>Returns:</p> Type Description <code>list of int</code> <p>The TT rank vector. Only available after :meth:<code>build</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.compression_ratio","title":"<code>compression_ratio</code>  <code>property</code>","text":"<p>Ratio of full tensor elements to TT storage elements.</p> <p>Returns:</p> Type Description <code>float</code> <p>Compression ratio (&gt; 1 means TT is more compact).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.total_build_evals","title":"<code>total_build_evals</code>  <code>property</code>","text":"<p>Total number of function evaluations used during build.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of function evaluations. Only meaningful after :meth:<code>build</code>.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.build","title":"<code>build(verbose=True, seed=None, method='cross')</code>","text":"<p>Build TT approximation and convert to Chebyshev coefficient cores.</p> <p>The build process has three stages:</p> <ol> <li>Generate Chebyshev grids. Compute Type I Chebyshev nodes    in each dimension, scaled to the specified domain.</li> <li>Build value cores. Either TT-Cross (evaluating at    \\(O(d \\cdot n \\cdot r^2)\\) strategically selected points) or    TT-SVD (evaluating the full \\(O(n^d)\\) tensor, then decomposing    via sequential SVD).</li> <li>Convert to coefficient cores. Apply DCT-II along the node    axis of each core to convert from function values at Chebyshev    nodes to Chebyshev expansion coefficients. This enables    evaluation at arbitrary (non-grid) points via the Chebyshev    polynomial inner product.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print build progress. Default is True.</p> <code>True</code> <code>seed</code> <code>int or None</code> <p>Random seed for TT-Cross initialization. Default is None. Ignored when <code>method='svd'</code>.</p> <code>None</code> <code>method</code> <code>``'cross'`` or ``'svd'``</code> <p>Build algorithm. <code>'cross'</code> (default) uses TT-Cross to evaluate the function at \\(O(d \\cdot n \\cdot r^2)\\) strategically selected points. <code>'svd'</code> builds the full tensor and decomposes via truncated SVD -- only feasible for moderate dimensions (\\(d \\leq 6\\)) but useful for validation.</p> <code>'cross'</code>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.eval","title":"<code>eval(point)</code>","text":"<p>Evaluate at a single point via TT inner product.</p> <p>Computes the Chebyshev interpolant value at an arbitrary point by contracting the pre-computed coefficient cores with Chebyshev polynomial values. For each dimension \\(k\\):</p> <ol> <li>Scale the query coordinate to \\([-1, 1]\\).</li> <li>Evaluate all Chebyshev polynomials \\(T_0, \\ldots, T_{n_k-1}\\).</li> <li>Contract with the coefficient core:    \\(v = \\sum_j q_j \\cdot \\text{core}[:, j, :]\\)</li> </ol> <p>The chain of contractions reduces to a scalar. Cost: \\(O(d \\cdot n \\cdot r^2)\\) per point.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Query point, one coordinate per dimension.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Interpolated value at the query point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.eval_batch","title":"<code>eval_batch(points)</code>","text":"<p>Evaluate at multiple points simultaneously.</p> <p>Vectorizes the TT inner product over all N points using <code>np.einsum</code> for batched matrix contractions. For each dimension, all N polynomial vectors are contracted with the coefficient core in a single einsum call, then all N chain multiplications proceed in parallel. Typical speedup is 15--20x over calling :meth:<code>eval</code> in a loop.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray of shape (N, num_dimensions)</code> <p>Query points.</p> required <p>Returns:</p> Type Description <code>ndarray of shape (N,)</code> <p>Interpolated values at each query point.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.eval_multi","title":"<code>eval_multi(point, derivative_orders)</code>","text":"<p>Evaluate with finite-difference derivatives at a single point.</p> <p>Uses central finite differences. The first entry in <code>derivative_orders</code> is typically <code>[0, 0, ..., 0]</code> for the function value; subsequent entries specify derivative orders per dimension.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>list of float</code> <p>Evaluation point in the full n-dimensional space.</p> required <code>derivative_orders</code> <code>list of list of int</code> <p>Each inner list specifies derivative order per dimension. Supports 0 (value), 1 (first derivative), and 2 (second derivative).</p> required <p>Returns:</p> Type Description <code>list of float</code> <p>One result per derivative order specification.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.error_estimate","title":"<code>error_estimate()</code>","text":"<p>Estimate interpolation error from Chebyshev coefficient cores.</p> <p>For each dimension d, takes the maximum magnitude of the last Chebyshev coefficient across all \"rows\" and \"columns\" of the core (i.e., max over left-rank and right-rank indices of <code>|core[:, -1, :]|</code>). Returns the sum across dimensions.</p> <p>This is an approximate analog of the ex ante error estimation from Ruiz &amp; Zeron (2021), Section 3.4, adapted for TT format.</p> <p>Returns:</p> Type Description <code>float</code> <p>Estimated interpolation error.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Return picklable state, excluding the original function.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Restore state from a pickled dict.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.save","title":"<code>save(path)</code>","text":"<p>Save the built TT interpolant to a file.</p> <p>The original function is not saved -- only the numerical data needed for evaluation. The saved file can be loaded with :meth:<code>load</code> without access to the original function.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Destination file path.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If <code>build()</code> has not been called.</p>"},{"location":"user-guide/tensor-train/#pychebyshev.tensor_train.ChebyshevTT.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a previously saved TT interpolant from a file.</p> <p>The loaded object can evaluate immediately; no rebuild is needed. The <code>function</code> attribute will be <code>None</code>. Assign a new function before calling <code>build()</code> again if a rebuild is desired.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or path - like</code> <p>Path to the saved file.</p> required <p>Returns:</p> Type Description <code>ChebyshevTT</code> <p>The restored TT interpolant.</p> <p>Warns:</p> Type Description <code>UserWarning</code> <p>If the file was saved with a different PyChebyshev version.</p> <code>.. warning::</code> <p>This method uses :mod:<code>pickle</code> internally. Pickle can execute arbitrary code during deserialization. Only load files you trust.</p>"},{"location":"user-guide/usage/","title":"Usage Patterns","text":""},{"location":"user-guide/usage/#basic-workflow","title":"Basic Workflow","text":"<p>Every PyChebyshev workflow follows three steps:</p> <ol> <li>Define a callable function</li> <li>Build the interpolant (evaluates at Chebyshev nodes, pre-computes weights)</li> <li>Query at arbitrary points</li> </ol> <pre><code>from pychebyshev import ChebyshevApproximation\n\ncheb = ChebyshevApproximation(func, num_dimensions, domain, n_nodes)\ncheb.build()\nresult = cheb.vectorized_eval(point, derivative_order)\n</code></pre>"},{"location":"user-guide/usage/#evaluation-methods","title":"Evaluation Methods","text":"<p>PyChebyshev provides several evaluation methods with different speed/safety tradeoffs:</p> Method Speed Safety Use When <code>eval()</code> Slowest Full validation Testing and debugging <code>vectorized_eval()</code> Fastest Full validation Default choice <code>vectorized_eval_multi()</code> Fastest (multi) Full validation Price + Greeks at same point <p>Why no JIT?</p> <p>Earlier versions offered a Numba JIT <code>fast_eval()</code> path, but <code>vectorized_eval()</code> is ~150x faster because it routes N-D tensor contractions through BLAS GEMV \u2014 a single optimized matrix-vector multiply per dimension. JIT compilation cannot beat BLAS for this workload. <code>fast_eval()</code> is deprecated and will be removed in a future version.</p>"},{"location":"user-guide/usage/#vectorized_eval-recommended","title":"<code>vectorized_eval()</code> \u2014 Recommended","text":"<p>Uses BLAS matrix-vector products. For 5D with 11 nodes, replaces 16,105 Python loop iterations with 5 BLAS calls:</p> <pre><code>price = cheb.vectorized_eval([100, 100, 1.0, 0.25, 0.05], [0, 0, 0, 0, 0])\n</code></pre>"},{"location":"user-guide/usage/#vectorized_eval_multi-best-for-multiple-derivatives","title":"<code>vectorized_eval_multi()</code> \u2014 Best for multiple derivatives","text":"<p>Pre-computes normalized barycentric weights once, reuses across all derivative orders:</p> <pre><code>results = cheb.vectorized_eval_multi(\n    [100, 100, 1.0, 0.25, 0.05],\n    [\n        [0, 0, 0, 0, 0],  # price\n        [1, 0, 0, 0, 0],  # delta (dV/dS)\n        [2, 0, 0, 0, 0],  # gamma (d\u00b2V/dS\u00b2)\n        [0, 0, 0, 1, 0],  # vega  (dV/d\u03c3)\n        [0, 0, 0, 0, 1],  # rho   (dV/dr)\n    ],\n)\nprice, delta, gamma, vega, rho = results\n</code></pre>"},{"location":"user-guide/usage/#batch-evaluation","title":"Batch Evaluation","text":"<p>For evaluating at many points:</p> <pre><code>import numpy as np\n\npoints = np.array([\n    [100, 100, 1.0, 0.25, 0.05],\n    [110, 100, 1.0, 0.25, 0.05],\n    [90, 100, 1.0, 0.25, 0.05],\n])\nprices = cheb.vectorized_eval_batch(points, [0, 0, 0, 0, 0])\n</code></pre>"},{"location":"user-guide/usage/#function-signature","title":"Function Signature","text":"<p>The function passed to <code>ChebyshevApproximation</code> must accept:</p> <ul> <li><code>point</code> \u2014 a list of floats (one per dimension)</li> <li><code>data</code> \u2014 arbitrary additional data (use <code>None</code> if not needed)</li> </ul> <pre><code>def my_func(point, data):\n    x, y, z = point\n    return x**2 + y * z\n</code></pre>"},{"location":"user-guide/usage/#next-steps","title":"Next Steps","text":"<ul> <li>Computing Greeks -- analytical derivatives via spectral differentiation</li> <li>Chebyshev Algebra -- combine interpolants via <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></li> <li>Chebyshev Calculus -- integration, rootfinding &amp; optimization on interpolants</li> <li>Error Estimation -- check accuracy without test points</li> <li>Saving &amp; Loading -- persist built interpolants for production</li> <li>For 5+ dimensions, see Tensor Train or Sliding Technique</li> </ul>"}]}